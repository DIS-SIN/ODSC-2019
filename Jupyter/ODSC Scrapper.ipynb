{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, List, Mapping, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.parse\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_html(url: str, \n",
    "             method: str, \n",
    "             data: Optional[dict] = None,\n",
    "             headers: Optional[dict] = None) -> str:\n",
    "    if method == \"POST\":\n",
    "        if data is not None:\n",
    "            data = urllib.parse.urlencode(data)\n",
    "            data = data.encode(\"ascii\")\n",
    "            if headers is not None:\n",
    "                req = urllib.request.Request(url, data, headers)\n",
    "            else:\n",
    "                req = urllib.request.Request(url, data)\n",
    "        elif headers is not None:\n",
    "            req = urllib.request.Request(url, headers)\n",
    "        else:\n",
    "            raise ValueError(\"Must provide data if making POST request\")\n",
    "    elif method == \"GET\":\n",
    "        if data is not None:\n",
    "            data = urllib.parse.urlencode(data)\n",
    "            url = url + '?' + data\n",
    "            if headers is not None:\n",
    "                req = urllib.request.Request(url, headers)\n",
    "        elif headers is not None:\n",
    "            req = urllib.request.Request(url,headers)\n",
    "        else:\n",
    "            req = urllib.request.Request(url)\n",
    "    else:\n",
    "        raise ValueError(f\"method {method} is not supported\")\n",
    "    \n",
    "    with urllib.request.urlopen(req) as response:\n",
    "        print(req.headers)\n",
    "        page = response.read()\n",
    "    return page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links_from_html(html: str) -> List[dict]:\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    links = [{\"parent\": link.parent, **link.attrs} for link in soup.find_all('a')]\n",
    "    return links\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PageHTML:\n",
    "    def __init__(self, url: str, **kwargs: Union[dict, int, str]) -> None:\n",
    "        self.vals = {'url': url, **kwargs}\n",
    "        self.url = url\n",
    "    \n",
    "    @property\n",
    "    def url(self) -> str:\n",
    "        return self._url\n",
    "    @property\n",
    "    def html(self) -> str:\n",
    "        self.updated = False\n",
    "        return self._html\n",
    "    @property\n",
    "    def soup(self) -> BeautifulSoup:\n",
    "        self.updated = False\n",
    "        return self._soup\n",
    "    @url.setter\n",
    "    def url(self, url) -> None:\n",
    "        if hasattr(self, 'url'):\n",
    "            if url != self.url:\n",
    "                self._url = url\n",
    "                self.vals['url'] = self._url\n",
    "                self.html = self.vals\n",
    "        else:\n",
    "            self.vals['url'] = url\n",
    "            self._url = url\n",
    "            self.html = self.vals\n",
    "    @html.setter\n",
    "    def html(self, vals: Union[str, Mapping[str,Union[str,dict]]]) -> None:\n",
    "        self.updated = True\n",
    "        if isinstance(vals,str):\n",
    "            req = urllib.request.Request(vals)\n",
    "        else:\n",
    "            if vals.get('url') is None:\n",
    "                raise ValueError(\"When providing a dictionary the url field must be present\")\n",
    "            if vals.get('method') == \"POST\":\n",
    "                if vals.get('data') is not None:\n",
    "                    data = urllib.parse.urlencode(vals['data'])\n",
    "                    data = data.encode('ascii')\n",
    "                    if vals.get('headers') is not None:\n",
    "                        req = urllib.request.Request(self.url, data, headers = vals.get('headers'))\n",
    "                    else:\n",
    "                        req = urllib.request.Request(self.url, data)\n",
    "                else:\n",
    "                    raise ValueError(\"When submitting a post request data field must not be none\")\n",
    "            else:\n",
    "                if vals.get('data') is not None:\n",
    "                    data = urllib.parse.urlencode(vals['data'])\n",
    "                    self.url = url + '?' + data\n",
    "                    if vals.get('headers') is not None:\n",
    "                        req = urllib.request.Request(self.url, headers = vals.get('headers'))\n",
    "                    else:\n",
    "                        req = urllib.request.Request(self.url)\n",
    "                elif vals.get('headers') is not None:\n",
    "                    req = urllib.request.Request(self.url, headers = vals.get('headers'))\n",
    "                else:\n",
    "                    req = urllib.request.Request(self.url)\n",
    "        self.request = req\n",
    "        print(self.request.headers)\n",
    "        with urllib.request.urlopen(req) as response:\n",
    "            self._html = response.read()\n",
    "            self.soup = self._html\n",
    "    \n",
    "    @soup.setter\n",
    "    def soup(self, html):\n",
    "        self._soup = BeautifulSoup(html, 'lxml')\n",
    "    \n",
    "    def refresh(self):\n",
    "        self.html = self.vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Position:\n",
    "    def __init__(self, position: str) -> None:\n",
    "        self.position = position\n",
    "    @property\n",
    "    def position(self) -> str:\n",
    "        return self._position\n",
    "    @position.setter\n",
    "    def position(self, position: str) -> None:\n",
    "        self._position = position\n",
    "    def __repr__(self):\n",
    "        return f\"Position {self.position}\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Organization:\n",
    "    def __init__(self, organization: str) -> None:\n",
    "        self.organization = organization\n",
    "    @property\n",
    "    def organization(self) -> str:\n",
    "        return self._organization\n",
    "    @organization.setter\n",
    "    def organization(self, organization: str) -> None:\n",
    "        self._organization = organization\n",
    "    def __repr__(self):\n",
    "        return f\"Organization {self.organization}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Presenter:\n",
    "    def __init__(self, parent: Tag) -> None:\n",
    "        self.parent = parent\n",
    "    @property\n",
    "    def parent(self) -> Tag:\n",
    "        return self._parent\n",
    "    @property\n",
    "    def artist_popover_element(self) -> Tag:\n",
    "        return self._artist_popover_element\n",
    "    @property\n",
    "    def presenter_bio(self) -> str:\n",
    "        return self._presenter_bio\n",
    "    @property\n",
    "    def artist_image_element(self):\n",
    "        return self._artist_image_element\n",
    "    @property\n",
    "    def presenter_image(self):\n",
    "        return self._presenter_image\n",
    "    @property\n",
    "    def artist_linkedin_element(self):\n",
    "        return self._artist_linkedin_element\n",
    "    @property\n",
    "    def presenter_linkedin(self):\n",
    "        return self._presenter_linkedin\n",
    "    @property\n",
    "    def artist_info_element(self):\n",
    "        return self._artist_info_element\n",
    "    @property\n",
    "    def artist_title_element(self):\n",
    "        return self._artist_title_element\n",
    "    @property\n",
    "    def artist_position_element(self):\n",
    "        return self._artist_position_element\n",
    "    @property\n",
    "    def title(self):\n",
    "        return self._title\n",
    "    @property\n",
    "    def name(self):\n",
    "        return self._name\n",
    "    @property\n",
    "    def organizations(self):\n",
    "        return self._organizations\n",
    "    @property\n",
    "    def positions(self):\n",
    "        return self._positions\n",
    "    @parent.setter\n",
    "    def parent(self, parent: Tag) -> None:\n",
    "        self.updated = True\n",
    "        self._parent = parent\n",
    "        if len(self._parent.find_all(class_ = \"tcode-artist-popover\")) > 0:\n",
    "            self.artist_popover_element = self._parent.find_all(class_ = \"tcode-artist-popover\")[0]\n",
    "        else:\n",
    "            self.artist_content_element = None\n",
    "            self.presenter_bio = None\n",
    "        if len(self._parent.find_all(class_ = \"tcode-es-artist-title-container\")) > 0:\n",
    "            self.artist_info_element = self._parent.find_all(class_ = \"tcode-es-artist-title-container\")[0]\n",
    "        else:\n",
    "            self._artist_info_element = None\n",
    "            self._positions = None\n",
    "            self._organizations = None\n",
    "            self._title = None\n",
    "            self._name = None\n",
    "    @artist_info_element.setter\n",
    "    def artist_info_element(self, artist_info_element: Tag) -> None:\n",
    "        self.updated = True\n",
    "        self._artist_info_element = artist_info_element\n",
    "        if self._artist_info_element.find(class_=\"tcode-es-artist-title\") is not None:\n",
    "            self.artist_title_element = self._artist_info_element.find(class_ =\"tcode-es-artist-title\")\n",
    "        else:\n",
    "            self._name = None\n",
    "            self._title = None\n",
    "        if self._artist_info_element.find(class_ = \"artist-position\") is not None:\n",
    "            self.artist_position_element = self._artist_info_element.find(class_ = \"artist-position\")\n",
    "        else:\n",
    "            self._organizations = None\n",
    "            self._positions = None\n",
    "    @artist_position_element.setter\n",
    "    def artist_position_element(self, artist_position_element: Tag) -> None:\n",
    "        self.updated = True\n",
    "        self._artist_position_element = artist_position_element\n",
    "        txt = self._artist_position_element.text\n",
    "        txt = txt.strip()\n",
    "        positions_organizations = txt.split('|')\n",
    "        if len(positions_organizations) == 1:\n",
    "            positions = positions_organizations[0]\n",
    "            positions = positions.split(',')\n",
    "            last_position = positions.pop(-1)\n",
    "            if last_position.find('and') != -1:\n",
    "                last_position = last_position.split('and')\n",
    "                positions.extend(last_position)\n",
    "            else:\n",
    "                positions.append(last_position)\n",
    "            self._positions = []\n",
    "            for pos in positions:\n",
    "                self._positions.append(Position(pos))\n",
    "            self._organizations = None\n",
    "        elif (len(positions_organizations) == 2 and \n",
    "              positions_organizations[-1] != '' or len(positions_organizations) == 3 and\n",
    "              positions_organizations[-1] == ''):\n",
    "            positions = positions_organizations[0]\n",
    "            positions = positions.split(',')\n",
    "            last_position = positions.pop(-1)\n",
    "            if last_position.find('and') != -1:\n",
    "                last_position = last_position.split('and')\n",
    "                positions.extend(last_position)\n",
    "            else:\n",
    "                positions.append(last_position)\n",
    "            self._positions = []\n",
    "            for pos in positions:\n",
    "                self._positions.append(Position(pos))\n",
    "            organizations = positions_organizations[1]\n",
    "            organizations = organizations.split(',')\n",
    "            last_organization = organizations.pop(-1)\n",
    "            if last_organization.find('and') != -1:\n",
    "                last_organization = last_organization.split('and')\n",
    "                organizations.extend(last_organization)\n",
    "            else:\n",
    "                organizations.append(last_organization)\n",
    "            self._organizations = []\n",
    "            for org in organizations:\n",
    "                self._organizations.append(Organization(org))\n",
    "        else:\n",
    "            self._organizations = None\n",
    "            self._positions = None\n",
    "            \n",
    "            \n",
    "            \n",
    "    @artist_title_element.setter\n",
    "    def artist_title_element(self,artist_title_element: Tag) -> None:\n",
    "        self.updated = True\n",
    "        self._artist_title_element = artist_title_element\n",
    "        txt = self._artist_title_element.text\n",
    "        txt = txt.strip()\n",
    "        name_title = txt.split(',')\n",
    "        if len(name_title) == 1:\n",
    "            self._name = name_title[0]\n",
    "            self._title = None\n",
    "        elif len(name_title) > 1:\n",
    "            self._name = name_title[0]\n",
    "            self._title = name_title[1]\n",
    "    @artist_popover_element.setter\n",
    "    def artist_popover_element(self, artist_popover_element: Tag) -> None:\n",
    "        self.updated = True\n",
    "        self._artist_popover_element = artist_popover_element\n",
    "        if self._artist_popover_element.find(class_=\"artist-content\") is not None:\n",
    "            self._presenter_bio = self._artist_popover_element.find(class_=\"artist-content\").text\n",
    "        else:\n",
    "            self._presenter_bio = None\n",
    "        if self._artist_popover_element.find(class_=\"artist-image\") is not None:\n",
    "            self.artist_image_element = self._artist_popover_element.find(class_=\"artist-image\")\n",
    "        else:\n",
    "            self._artist_image = None\n",
    "            self._presenter_image = None\n",
    "        if self._artist_popover_element.find(class_=\"tcode-ico-linkedin\") is not None:\n",
    "            self.artist_linkedin_element = self._artist_popover_element.find(class_=\"tcode-ico-linkedin\")\n",
    "        else:\n",
    "            self._artist_linkedin_element = None\n",
    "            self._presenter_linkedin = None\n",
    "    @artist_image_element.setter\n",
    "    def artist_image_element(self,artist_image_element: Tag) -> None:\n",
    "        self.updated = True\n",
    "        self._artist_image_element = artist_image_element\n",
    "        if self._artist_image_element.find('img') is not None:\n",
    "            self._presenter_image = self._artist_image_element.find('img').get('src')\n",
    "        else:\n",
    "            self._presenter_image = None\n",
    "    @artist_linkedin_element.setter\n",
    "    def artist_linkedin_element(self, artist_linkedin_element: Tag) -> None:\n",
    "        self.updated = True\n",
    "        self._artist_linkedin_element = artist_linkedin_element\n",
    "        self._presenter_linkedin = self._artist_linkedin_element.get('href')\n",
    "            \n",
    "            \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Category:\n",
    "    def __init__(self, category: str) -> None:\n",
    "        self.category = category\n",
    "    @property\n",
    "    def category(self):\n",
    "        return self._category\n",
    "    @category.setter\n",
    "    def category(self, category: str) -> None:\n",
    "        self.updated = True\n",
    "        self._category = category\n",
    "    def __repr__(self):\n",
    "        return f\"Category {self.category}\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScheduleItem:\n",
    "    def __init__(self, parent: Tag) -> None:\n",
    "        self.parent = parent\n",
    "    @property\n",
    "    def parent(self) -> Tag:\n",
    "        self.updated = False\n",
    "        return self._parent\n",
    "    @property\n",
    "    def title_element(self) -> Tag:\n",
    "        self.updated = False\n",
    "        return self._title_element\n",
    "    @property\n",
    "    def time_element(self) -> Tag:\n",
    "        self.updated = False\n",
    "        return self._time_element\n",
    "    @property\n",
    "    def excerpt_element(self) -> Tag:\n",
    "        return self._excerpt_element\n",
    "    @property\n",
    "    def excerpt_text_element(self) -> Tag:\n",
    "        return self._excerpt_text_element\n",
    "    @property\n",
    "    def excerpt_p_elements(self) -> List[Tag]:\n",
    "        return self._excerpt_p_element\n",
    "    @property\n",
    "    def excerpt_categories_element(self) -> Tag:\n",
    "        return self._excerpt_category_element\n",
    "    @property\n",
    "    def categories_text(self) -> str:\n",
    "        return self._categories_text\n",
    "    @property\n",
    "    def presenters_element(self) -> List[Tag]:\n",
    "        return self._presenters_element\n",
    "    @property\n",
    "    def title(self) -> str:\n",
    "        return self._title\n",
    "    @property\n",
    "    def day(self) -> str:\n",
    "        return self._day\n",
    "    @property\n",
    "    def time(self) -> str:\n",
    "        return self._time\n",
    "    @property\n",
    "    def datetime(self) -> datetime.datetime:\n",
    "        month_day = self._day\n",
    "        month_day = month_day.strip('st')\n",
    "        month_day = month_day.strip('rd')\n",
    "        month_day = month_day.strip('th')\n",
    "        year_month_day = \"2019-\" + month_day\n",
    "        if self._time is not None:\n",
    "            year_month_day = year_month_day + \" \" + self._time\n",
    "            return datetime.datetime.strptime(year_month_day, '%Y-%B-%d %H:%M')\n",
    "        return datetime.datetime.strptime(year_month_day, '%Y-%B-%d')\n",
    "    @property\n",
    "    def excerpt(self) -> str:\n",
    "        return self._excerpt\n",
    "    @property\n",
    "    def presenters(self) -> List[dict]:\n",
    "        return self._presenters\n",
    "    @property\n",
    "    def categories(self) -> List['Category']:\n",
    "        return self._categories\n",
    "    @parent.setter\n",
    "    def parent(self, parent) -> None:\n",
    "        self.updated = True\n",
    "        self._parent = parent\n",
    "        self._day = parent.get('data-location')\n",
    "        self.title_element = parent.find_all('div', class_ = 'event-title')[0]\n",
    "        if len(parent.find_all('div', class_ = \"event-time\")) > 0:\n",
    "            self.time_element = parent.find_all('div', class_ = \"event-time\")[0]\n",
    "        else:\n",
    "            self._time = None\n",
    "            self._time_element = None\n",
    "        if len(parent.find_all('div', class_ = \"event-excerpt\")) > 0:\n",
    "            self.excerpt_element = parent.find_all('div', class_ = \"event-excerpt\")[0]\n",
    "        else:\n",
    "            self._excerpt_element = None\n",
    "            self._excerpt_text_element = None\n",
    "            self._excerpt_categories_element = None\n",
    "            self._excerpt_p_elements = None\n",
    "            self._categories_text = None\n",
    "            self._presenters_element = None\n",
    "            self._presenters = None\n",
    "            self._excerpt = None\n",
    "            self._categories = None\n",
    "    @title_element.setter\n",
    "    def title_element(self, title_element: Tag) -> None:\n",
    "        self.updated = True\n",
    "        self._title_element = title_element\n",
    "        self._title = str(self._title_element.contents[0])\n",
    "    @time_element.setter\n",
    "    def time_element(self, time_element: Tag) -> None:\n",
    "        self.updated = True\n",
    "        self._time_element = time_element\n",
    "        self._time = self._time_element.find_all(class_ = \"time-starts\")[0].text\n",
    "    @excerpt_element.setter\n",
    "    def excerpt_element(self, excerpt_element: Tag) -> None:\n",
    "        self.updated = True\n",
    "        self._excerpt_element = excerpt_element\n",
    "        if len(excerpt_element.find_all(class_ = 'event-content')) > 0:\n",
    "            self.excerpt_text_element = excerpt_element.find_all(class_ = 'event-content')[0]\n",
    "        else:\n",
    "            self._excerpt_text_element = None\n",
    "            self._excerpt = None\n",
    "            self._categories_text = None\n",
    "            self._categories = None\n",
    "            self._excerpt_categories_element\n",
    "        if len(excerpt_element.find_all(class_ = \"artist-row\")) > 0:\n",
    "            self.presenters_element = excerpt_element.find_all(class_ = \"artist-row\")\n",
    "        else:\n",
    "            self._presenters_element = None\n",
    "            self._presenters = None\n",
    "    @presenters_element.setter\n",
    "    def presenters_element(self, presenters_element: List[Tag]) -> None:\n",
    "        self.updated = True\n",
    "        self._presenters_element = presenters_element\n",
    "        self._presenters = []\n",
    "        for elem in self._presenters_element:\n",
    "            self._presenters.append(Presenter(elem))\n",
    "    @excerpt_text_element.setter\n",
    "    def excerpt_text_element(self, excerpt_text_element: Tag) -> None:\n",
    "        self.updated = True\n",
    "        self._excerpt_text_element = excerpt_text_element\n",
    "        if len(excerpt_text_element.find_all('strong')) > 0:\n",
    "            self.excerpt_categories_element = excerpt_text_element.find_all('strong')[0]\n",
    "        else:\n",
    "            self._excerpt_categories_element = None\n",
    "            self._categories_text = None\n",
    "            self._categories = None\n",
    "        excerpt_p_elements = []\n",
    "        for elem in excerpt_text_element.find_all('p'):\n",
    "            if len(elem.find_all('strong')) == 0 or len(elem.select('strong a')) > 0:\n",
    "                if elem.text != \"&nbsp;\":\n",
    "                    excerpt_p_elements.append(elem)\n",
    "        if len(excerpt_p_elements) >= 1:\n",
    "            self.excerpt_p_elements = excerpt_p_elements\n",
    "            \n",
    "        else:\n",
    "            self._excerpt_p_elements = None\n",
    "            self._excerpt = None\n",
    "    @excerpt_p_elements.setter\n",
    "    def excerpt_p_elements(self, excerpt_p_elements: List[Tag]) -> None:\n",
    "        self.updated = True\n",
    "        self._excerpt_p_elements = excerpt_p_elements\n",
    "        excerpt = \"\"\n",
    "        for elem in self._excerpt_p_elements:\n",
    "            if elem.find('span') is None:\n",
    "                excerpt += elem.text + \"\\n\"\n",
    "            else:\n",
    "                excerpt_span = elem.find('span')\n",
    "                if excerpt_span.get('data-sheets-value') is not None:\n",
    "                    excerpt = json.loads(excerpt_span.get('data-sheets-value'))['2']\n",
    "                    break  \n",
    "        excerpt = excerpt.lstrip(\"\\n\")\n",
    "        self._excerpt = excerpt.replace('more details', '')\n",
    "    @excerpt_categories_element.setter\n",
    "    def excerpt_categories_element(self, excerpt_category_element: Tag) -> None:\n",
    "        self.updated = True\n",
    "        self._excerpt_category_element = excerpt_category_element\n",
    "        self.categories_text = excerpt_category_element.text\n",
    "    @categories_text.setter\n",
    "    def categories_text(self, categories_text: Tag) -> None:\n",
    "        self.updated = True\n",
    "        self._categories_text = categories_text\n",
    "        categories_list = [cat.strip(' ').replace('&nbsp;', '') for cat in self._categories_text.split('|')]\n",
    "        self._categories = [Category(cat) for cat in categories_list]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SchedulePage(PageHTML):\n",
    "    def __init__(self, url: str, **kwargs: Union[dict, str, int]) -> None:\n",
    "        if url.find('odsc.com') == -1:\n",
    "            raise ValueError('url must be an odsc schedule page')\n",
    "        elif url.find('schedule') == -1:\n",
    "            raise ValueError('odsc link specified is not a schedule page!')\n",
    "        super(SchedulePage, self).__init__(url, **kwargs)\n",
    "    @property\n",
    "    def items(self) -> List['ScheduleItem']:\n",
    "        if self.updated == True:\n",
    "            self.items = self.soup\n",
    "        return self._items\n",
    "    @items.setter\n",
    "    def items(self, soup: BeautifulSoup) -> None:\n",
    "        self._items_elements = self.soup.find_all(class_ = \"scheduled-events\")[0]\n",
    "        self._items = []\n",
    "        count = 0\n",
    "        for child in self._items_elements.children:\n",
    "            if (isinstance(child, Tag) and \n",
    "                child.has_attr('class') and\n",
    "               'scheduled-event' in child['class']):\n",
    "                count += 1\n",
    "                item = ScheduleItem(child)\n",
    "                self._items.append(item)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'User-agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/535.19 (KHTML, like Gecko) Chrome/18.0.1025.45 Safari/535.19'}\n"
     ]
    }
   ],
   "source": [
    "page = SchedulePage('https://odsc.com/boston/east-2019-schedule',\n",
    "                   headers = {\n",
    "                       'User-Agent': \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/535.19 (KHTML, like Gecko) Chrome/18.0.1025.45 Safari/535.19\"\n",
    "                   })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page.updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title Advanced Data Analysis, Dashboards and Visualization\n",
      "day april-30th\n",
      "time 09:00\n",
      "datetime 2019-04-30 09:00:00\n",
      "excerpt In this training session you will learn to turn your data into interactive dashboards, how to create stories with data and share these dashboards with your audience. You will get hands on training on how to create stories with dashboards and share these dashboards with your audience. We will begin with a quick refresher of basics about design and information literacy and discussions about practices for creating charts and storytelling utilizing best visual practices. Whether your goal is to explain an insight or let your audience explore data insights, using Tableau Public’s (free to use tool) simple drag-and-drop user interface makes the task easy and enjoyable. \n",
      "You will learn to create various Table Calculations, Sets, Filters, Level of Detail expressions, Animations, predictive analytics using forecast functions and understanding Clustering. You will learn to integrate R and Tableau and how to use R within Tableau. Learn advance charts such as Waterfall charts, Pareto charts, Gantt Charts, Control Charts and Box and Whisker’s plot. You will also learn mapping, using parameters and other visual functionalities. You will learn about data preparation – joins, blending, union.\n",
      "You will gain skills to analyze and visualize complex data sets with ease with minimum programming. In short, you will be guided using couple of data sets and will be taught to build a compelling and convincing story. You will build those stories with best visual practices. This session is for anyone who works with data is interested in building dashboards and communicate insights about data with stories.\n",
      "\n",
      "presenter_bio \n",
      "Nirav Shah is the Founder of OnPoint Insights, a data analytics, software services and staff augmentation consultancy based in Boston. He has 15 years of industry experience – mainly in consulting on data analytics, big data modeling, process analytics and real-time  data solutions, and training customers in data analytics,dashboards and data visualization.\n",
      "He consults and teaches in applying data analytics for manufacturing, operations, supply chain, process control strategies with clients to improve manufacturing process and operational efficiency. He has implemented real- time process monitoring data analytics and fault detection systems for leading bio-pharma customers and clients from other industries such as chemical, pulp and paper, food and beverages. He helps customers in providing better process insights using data driven solutions.\n",
      "He is also an Adjunct Professor at University of Massachusetts in Boston where he teaches Engineering Process Analytics, a graduate level class in Engineering Department,  teaches Business Analytics and Dashboard Visualization at a technical college and conducts BootCamps and Workshops at General Assembly Boston.  He has  taught courses and conducted workshops to industry clients on Multivariate Data Analysis for ten years. He has spoken at various conferences ( ODSC East Boston, ODSC India, Global AI).\n",
      "He completed his dual Masters in Chemical and Computer Engineering from University of Massachusetts and an MBA in Entrepreneurship from Babson College.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2019/04/Nirav-Shah-120x120.png\n",
      "presenter_linkedin https://www.linkedin.com/in/niravdshah/\n",
      "presenter_title None\n",
      "presenter_name Nirav Shah\n",
      "presenter_orgs [Organization  OnPoint Insights]\n",
      "presenter_positions [Position Founder ]\n",
      "categories [Category Training, Category Data Visualization, Category Open Source Data Science, Category Intermediat]\n",
      "\n",
      "title Introduction to RMarkdown in Shiny\n",
      "day may-1st\n",
      "time 09:00\n",
      "datetime 2019-05-01 09:00:00\n",
      "excerpt Markdown Primer (45 minutes)Structure Documents with Sections and SubsectionsFormatting TextCreating Ordered and Unordered ListsMaking LinksNumber SectionsInclude Table of Contents\n",
      "Integrate R Code (30 minutes)Insert Code ChunksHide CodeSet Chunk OptionsDraw PlotsSpeed Up Code with Caching\n",
      "Build RMarkdown Slideshows (20 minutes)Understand Slide StructureCreate SectionsSet Background ImagesInclude Speaker NotesOpen Slides in Speaker Mode\n",
      "Develop Flexdashboards (30 minutes)Start with the Flexdashboard LayoutDesign Columns and RowsUse Multiple PagesCreate Social SharingInclude Code\n",
      "Shiny InputsDrop DownsTextRadioChecks\n",
      "Shiny OutputsTextTablesPlots\n",
      "Reactive Expressions\n",
      "HTML WidgetsInteractive PlotsInteractive MapsInteractive Tables\n",
      "Shiny Layouts UI and Server Files User Interface\n",
      "presenter_bio \n",
      "Jared Lander is the Chief Data Scientist of Lander Analytics a data science consultancy based in New York City, the Organizer of the New York Open Statistical Programming Meetup and the New York R Conference and an Adjunct Professor of Statistics at Columbia University. With a masters from Columbia University in statistics and a bachelors from Muhlenberg College in mathematics, he has experience in both academic research and industry. His work for both large and small organizations ranges from music and fund raising to finance and humanitarian relief efforts.\n",
      "He specializes in data management, multilevel models, machine learning, generalized linear models, data management and statistical computing. He is the author of R for Everyone: Advanced Analytics and Graphics, a book about R Programming geared toward Data Scientists and Non-Statisticians alike and is creating a course on glmnet with DataCamp.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2017/05/Jared-Lander.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/jaredlander/\n",
      "presenter_title None\n",
      "presenter_name Jared Lander\n",
      "presenter_orgs [Organization  Columbia University]\n",
      "presenter_positions [Position Author, Position  R Programming Expert, Position  Statistics Professor  ]\n",
      "categories [Category Training, Category Data Visualization, Category Open Source Data Science, Category Intermediate]\n",
      "\n",
      "title Integrating Pandas with Scikit-Learn, an Exciting New Workflow\n",
      "day april-30th\n",
      "time 09:00\n",
      "datetime 2019-04-30 09:00:00\n",
      "excerpt  \n",
      "For Python data scientists, a typical workflow consists of using Pandas for exploratory data analysis before turning to Scikit-Learn for machine learning. Pandas and Scikit-Learn arose independently, each focusing on their specific tasks, and were never specifically designed to be integrated together. There was never a clearly defined and standardized process for transitioning between the two libraries. This lack of a concrete handoff lead to practitioners creating a variety of markedly different workflows to make this transition.\n",
      "One of the main hurdles facing the Pandas to Scikit-Learn transition was the handling of string columns. Inputs to Scikit-Learn’s machine learning models only allow for numeric arrays. The common scenario of taking a Pandas DataFrame with string columns and converting it to an array of only numeric values was quite painful. Yet another hurdle, was processing separate groupings of columns with separate functions.\n",
      "With the recent release of Scikit-Learn version 0.20, many workflows will start looking similar. The brand new ColumnTransformer allows for direct Pandas integration to Scikit-Learn. It applies separate transformations to specific subsets of columns. The upgraded OneHotEncoder standardizes the encoding of string columns. Before, it only encoded columns containing numeric categorical data.\n",
      "In this hands-on tutorial, we will use these new additions to Scikit-Learn to build a modern, robust, and efficient workflow for those starting from a Pandas DataFrame. There will be ample practice problems and detailed notes available so that you can use it immediately upon completion…\n",
      "\n",
      "presenter_bio \n",
      "Ted Petrou is the author of Pandas Cookbook and founder of both Dunder Data and the Houston Data Science Meetup group. He worked as a data scientist at Schlumberger where he spent the vast majority of his time exploring data. Ted received his Master’s degree in statistics from Rice University and used his analytical skills to play poker professionally and teach math before becoming a data scientist.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2018/07/Ted-Petrou-120x120.png\n",
      "presenter_linkedin https://www.linkedin.com/in/tedpetrou/\n",
      "presenter_title None\n",
      "presenter_name Ted Petrou\n",
      "presenter_orgs [Organization  Dunder Data]\n",
      "presenter_positions [Position Founder ]\n",
      "categories [Category Training, Category  Machine Learning, Category  Open Source Data Science, Category  Intermediate-Advanced]\n",
      "\n",
      "title How Should We (Correctly) Compare Graphs?\n",
      "day may-1st\n",
      "time 09:00\n",
      "datetime 2019-05-01 09:00:00\n",
      "excerpt  \n",
      "Graph representations of real-world phenomena are ubiquitous – from social and information networks, to technological, biological, chemical, and brain networks. Many graph mining tasks require a distance (or, conversely, a similarity) measure between graphs. Examples include clustering of graphs and anomaly detection, nearest neighbor and similarity search, pattern recognition, and transfer learning. Such tasks find applications in diverse areas including image processing, chemistry, and social network analysis, to name a few.\n",
      "Intuitively, given two graphs, their distance is a score quantifying their structural differences. A highly desirable property for such a score is that it is a metric, i.e., it is non-negative, symmetric, positive-definite, and, crucially, satisfies the triangle inequality. Metrics exhibit significant computational advantages over non-metrics. For example, operations such as nearest-neighbor search, clustering, outlier detection, and diameter computation have known fast algorithms precisely when performed over objects embedded in a metric space.\n",
      "Unfortunately, algorithms to compute several classic distances between graphs do not scale to large graphs; other distances do not satisfy all of the metric properties: non-negativity, positive definiteness, symmetry, and triangle inequality.\n",
      "The purpose of this tutorial is to go over the recent and expanding literature of graph metric spaces, focusing specifically on tractable metrics. Furthermore, we also explain how to compute the distance between n graphs in a way that the resulting distance satisfy a generalization of the triangle inequality to n elements, and is still tractable…\n",
      "\n",
      "presenter_bio \n",
      "Sam Safavi completed his Ph.D. in Electrical and Computer Engineering at Tufts University. He got his M.Sc. degree in Automated Systems and Control from University of Sheffield, and his B.Sc. degree in Electrical Engineering from University of Tehran. After his Ph.D., he worked with Prof. Bento as a post-doctoral researcher at the Computer Science department at Boston College, where he studied measures of distance between multiple graphs. Sam has recently joined Wise Systems as an applied research scientist. His research interests include distributed algorithms, machine learning and optimization.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2019/04/Sam-Safavi-120x120.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/sam-safavi-42b901132/\n",
      "presenter_title  PhD\n",
      "presenter_name Sam Safavi\n",
      "presenter_orgs [Organization  Boston College]\n",
      "presenter_positions [Position Postdoctoral Research Scientist ]\n",
      "categories [Category Tutorial, Category  Data Visualization, Category  Intermediate-Advanced]\n",
      "\n",
      "title TFX: Production ML Pipelines with TensorFlow\n",
      "day april-30th\n",
      "time 09:00\n",
      "datetime 2019-04-30 09:00:00\n",
      "excerpt Putting machine learning models into production is now mission critical for every business - no matter what size. \n",
      "\n",
      "TensorFlow is the industry-leading platform for developing, modeling, and serving deep learning solutions. But putting together a complete pipeline for deploying and maintaining a production application of AI and deep learning is much more than training a model. Google has taken years of experience in developing production ML pipelines and offered the open source community TensorFlow Extended (TFX), an open source version of tools and libraries that Google uses internally.\n",
      "\n",
      "Learn what’s involved in creating a production pipeline, and walk through working code in an example pipeline with experts from Google. You’ll be able to take what you learn and get started on creating your own pipelines for your applications.\n",
      "presenter_bio \n",
      "Coming soon!\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2019/02/Robert-Crowe-120x120.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/robert-crowe-a018725/\n",
      "presenter_title None\n",
      "presenter_name Robert Crowe\n",
      "presenter_orgs [Organization  Google]\n",
      "presenter_positions [Position Developer Advocate, Position  TensorFlow ]\n",
      "categories [Category Training, Category  Open Source Data Science, Category  Deep Learning, Category  Intermediate]\n",
      "\n",
      "title Human-Centered Data Science – When the Left Brain Meets the Right Brain\n",
      "day may-1st\n",
      "time 09:00\n",
      "datetime 2019-05-01 09:00:00\n",
      "excerpt We will present two different dimensions of the practice of data science, specifically data storytelling (including data visualization) and data literacy. There will be short presentations, integrated with interactive sessions, group activities, and brief moments of brain and body exercise. The combination of these various activities is aimed at demonstrating and practicing the concepts being presented. The Data Literacy theme component will include a section on \"data profiling - having a first date with your data\", focusing on getting acquainted with all the facets, characteristics, features (good and bad), and types of your data. This theme will also include a section on matching models to algorithms to data types to the questions being asked. The Data Storytelling theme component will include sections on the neuroscience of visual displays of evidence (visual analytics) for decision-making and include a component on user-centered design in data science. Design thinking, empathy, consultative practice, and the BI Dashboard Formula (BIDF) methodology will be emphasized. The combination of the two themes (data literacy and data storytelling) will be made more concrete through exercises in small breakout groups. Each group will be given a sample problem, then asked to take a data science approach (modeling, visualization, storytelling) to address the three fundamental questions that we should always consider in our projects: What? So what? Now what? The workshop participant will come away with design tips, tricks, and tools for better human-centered data science. The goal is for your next data science project and presentation to be your best ever. As Maya Angelou said so eloquently, “people will forget what you said, people will forget what you did, but people will never forget how you made them feel.” Make your data science matter by demonstrating why and how it matters.\n",
      "presenter_bio \n",
      "Dr. Kirk Borne is the Principal Data Scientist and an Executive Advisor at global technology and consulting firm Booz Allen Hamilton. In those roles, he focuses on applications of data science, data management, machine learning, A.I., and modeling across a wide variety of disciplines. He also provides training and mentoring to executives and data scientists within numerous external organizations, industries, agencies, and partners in the use of large data repositories and machine learning for discovery, decision support, and innovation. Previously, he was Professor of Astrophysics and Computational Science at George Mason University for 12 years where he did research, taught, and advised students in data science. Prior to that, Kirk spent nearly 20 years supporting data systems activities on NASA space science programs, which included a period as NASA’s Data Archive Project Scientist for the Hubble Space Telescope. Dr. Borne has a B.S. degree in Physics from LSU, and a Ph.D. in Astronomy from Caltech. In 2016 he was elected Fellow of the International Astrostatistics Association for his lifelong contributions to big data research in astronomy. As a global speaker, he has given hundreds of invited talks worldwide, including conference keynote presentations at many dozens of data science, A.I. and big data analytics events globally. He is an active contributor on social media, where he has been named consistently among the top worldwide influencers in big data and data science since 2013. He was recently identified as the #1 digital influencer worldwide for 2018-2019. You can follow him on Twitter at @KirkDBorne.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2019/01/Kirk-Borne-120x120.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/kirkdborne/\n",
      "presenter_title None\n",
      "presenter_name Dr. Kirk Borne\n",
      "presenter_orgs [Organization  Booz Allen Hamilton]\n",
      "presenter_positions [Position Principal Data Scientist ]\n",
      "presenter_bio \n",
      "Mico Yuk (@micoyuk) is the founder of BI Brainz and the BI Dashboard Formula (BIDF) methodology, where she has trained thousands globally how to strategically use the power of data visualization to enhance the decision making process. Her inventive approach fuses Enterprise Visual Storytelling with her proprietary BI Dashboard Formula Methodology(BIDF). Mico’s ability to strategically use the power of data visualization to enhance the decision making process, develop analytics portfolios that business users love and help gain ROI from their Business Intelligence investment, has been sought out by several high-profile Fortune 500 companies: Shell, FedEx, Nestle, Qatargas, Ericsson, Procter & Gamble, Kimberly-Clark, FedEx and more. She has also authored, Data Visualization for Dummies (Wiley 2014).\n",
      "Her ‘blunt’ twitter comments and blogs have been mentioned on tech websites and blogs. Since 2010 she continues to be a sought after global keynote speaker and trainer, and was named one of the Top 50 Analytics Bloggers to follow by SAP. Some of her featured keynotes include Microsoft PASS Business Analytics Conference, MasteringSAP BI, Saloon BI, BOAK, and Big Data World in London to name a few. This year she’s a much anticipated keynote at the first Facebook’s Women in Analytics Conference at their headquarters in Menlo Park. In June she will be returning to Real Business Intelligence Conference at MIT as a featured speaker for the second year in a row.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2019/01/Mico-Yuk-120x120.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/micoyuk\n",
      "presenter_title None\n",
      "presenter_name Mico Yuk\n",
      "presenter_orgs [Organization  BI Brainz , Organization  the BI Dashboard Formula]\n",
      "presenter_positions [Position CEO , Position  Founder ]\n",
      "categories [Category Training, Category  Data Visualization, Category  Intermediate]\n",
      "\n",
      "title Introduction to Machine Learning\n",
      "day april-30th\n",
      "time 09:00\n",
      "datetime 2019-04-30 09:00:00\n",
      "excerpt Machine learning has become an indispensable tool across many areas of research and commercial applications. From text-to-speech for your phone to detecting the Higgs boson, machine learning excells at extracting knowledge from large amounts of data. This talk will give a general introduction to machine learning, as well as introduce practical tools for you to apply machine learning in your research. We will focus on one particularly important subfield of machine learning, supervised learning. The goal of supervised learning is to \"\"learn\"\" a function that maps inputs x to an output y, by using a collection of training data consisting of input-output pairs. We will walk through formalizing a problem as a supervised machine learning problem, creating the necessary training data and applying and evaluating a machine learning algorithm. The talk should give you all the necessary background to start using machine learning yourself.\n",
      "presenter_bio \n",
      "Andreas Mueller received his MS degree in Mathematics (Dipl.-Math.) in 2008 from the Department of Mathematics at the University of Bonn. In 2013, he finalized his PhD thesis at the Institute for Computer Science at the University of Bonn. After working as a machine learning scientist at the Amazon Development Center Germany in Berlin for a year, he joined the Center for Data Science at the New York University in the end of 2014. In his current position as assistant research engineer at the Center for Data Science, he works on open source tools for machine learning and data science. He is one of the core contributors of scikit-learn, a machine learning toolkit widely used in industry and academia, for several years, and has authored and contributed to a number of open source projects related to machine learning.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2015/12/Andreas-Mueller-1.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/andreas-mueller-b370265a/\n",
      "presenter_title  PhD\n",
      "presenter_name Andreas Mueller\n",
      "presenter_orgs None\n",
      "presenter_positions [Position Core Contributor of scikit-learn , Position  Author of Introduction to Machine Learning with Python]\n",
      "presenter_bio \n",
      "Thomas Fan is a Software Developer at Columbia University’s Data Science Institute. He collaborates with the scikit-learn community to develop features, review code, and resolve issues. On his free time, Thomas contributes to skorch, a scikit-learn compatible neural network library that wraps PyTorch.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2019/03/Thomas-Fan-1-120x120.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/thomasjpfan/\n",
      "presenter_title None\n",
      "presenter_name Thomas Fan\n",
      "presenter_orgs [Organization  Columbia Data Science Institute]\n",
      "presenter_positions [Position Software Developer - Machine Learning ]\n",
      "categories [Category Training, Category Kickstarter, Category Machine Learning, Category Beginner-Intermediate-Advanced]\n",
      "\n",
      "title Introduction to Data Science\n",
      "day april-30th\n",
      "time 09:00\n",
      "datetime 2019-04-30 09:00:00\n",
      "excerpt Curious about Data Science? Self-taught on some aspects, but missing the big picture? Well you’ve got to start somewhere and this session is the place to do it. This session will cover, at a layman’s level, some of the basic concepts of data science. In a conversational format, we will discuss: What are the differences between Big Data and Data Science – and why aren’t they the same thing? What distinguishes descriptive, predictive, and prescriptive analytics? What purpose do predictive models serve in a practical context? What kinds of models are there and what do they tell us? What is the difference between supervised and unsupervised learning? What are some common pitfalls that turn good ideas into bad science? During this session, attendees will learn the difference between k-nearest neighbor and k-means clustering, understand the reasons why we do normalize and don’t overfit, and grasp the meaning of No Free Lunch.\n",
      "presenter_bio \n",
      "Todd is a Data Science Evangelist at Data Robot. For more than 20 years, Todd has been highly respected as both a technologist and a trainer. As a tech, he has seen that world from many perspectives: “data guy” and developer; architect, analyst and consultant. As a trainer, he has designed and covered subject matter from operating systems to end-user applications, with an emphasis on data and programming. As a strong advocate for knowledge sharing, he combines his experience in technology and education to impart real-world use cases to students and users of analytics solutions across multiple industries. He is a regular contributor to the community of analytics and technology user groups in the Boston area, writes and teaches on many topics, and looks forward to the next time he can strap on a dive mask and get wet.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2018/05/Todd-Cioffi.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/toddcioffi/\n",
      "presenter_title None\n",
      "presenter_name Todd Cioffi\n",
      "presenter_orgs [Organization  DataRobot]\n",
      "presenter_positions [Position Data Science Evangelist ]\n",
      "categories [Category Training, Category Kickstarter, Category Beginner-Intermediate-Advanced]\n",
      "\n",
      "title AI/ML Algorithmic Based Recommendations for Cost and Time Effective Hiring Practices\n",
      "day may-1st\n",
      "time 09:00\n",
      "datetime 2019-05-01 09:00:00\n",
      "excerpt Despite the advent of big data, predicative analytics and artificial intelligence, the $200 billion worldwide recruitment market is driven predominantly by a human/manual process that is prone to inefficiency and inaccuracy. \n",
      "\n",
      "Bad hires cost employers nearly 30 percent of an employee’s annual earnings. While companies spend millions on recruitment advertising annually, using strategies based and past performance and little more than gut-instinct. \n",
      "\n",
      "There is stiff competition for talent in today’s job market amidst the tight labor market and increasing expectations of job seekers. Employers are challenged to fill headcount in both a time efficient and cost-effective manner. They need much better predictive recommendations to improve their recruiting marketing spend to hire cheaper and faster. \n",
      "\n",
      "iCIMS, the world’s leading best-in-class recruitment software provider, applies data science practices to analyze the hiring activities 75 million applicants and 288 million visitors to the career sites of more than 4,000 companies hosted on their proprietary database in 2018 alone.\n",
      "\n",
      "Join these sessions to discuss and explore how to:\n",
      "\n",
      "• Apply artificial intelligence/deep learning and machine learning methods to develop a recommendation engine for the best hiring practices. A variety of artificial intelligence techniques ranging from natural language processing, classification machine learning models and deep learning will be examined.\n",
      "• Solve for the problems of recruiters and HR professionals using artificial intelligence and machine learning without inheriting human bias and error \n",
      "• Cleanse, normalize, analyze and predict the data behind massive amounts of hiring activity\n",
      "presenter_bio \n",
      "Dr. Dastgeer Shaikh, Ph.D., is a senior data scientist at iCIMS, a leading provider of recruitment software solutions for global enterprise companies. At iCIMS, he has actively been engaged in artificial intelligence (AI) and machine learning (ML) algorithm development work aimed at producing insights into predictive recruiting job market data to help employers make smarter, more informed hiring decisions.\n",
      "By means of implementation of cutting-edge technology such as TensorFlow with Keras python framework, Dr. Shaikh has developed an AI model that predicts candidates for open jobs that employers post online and suggests relevant open jobs for candidates. He has extensive experience in working with numerous data science centric state-of-the-arts such as Natural Language Processing, Bayesian Models, Deep Learning, Neural Network, Ensemble Modeling, linear and nonlinear modeling, Data Cleansing, building python API’s for automation, time series analysis, statistics and mathematical models.\n",
      "Dr. Shaikh’s interests include financial, aerospace and social-related AI/ML modeling. He has built many AI and machine learning driven models to detect transaction risks, predict space weather, social behavior, etc. Dr. Shaikh has many publications during his tenure as PhD and post-doctoral researcher in Computational Physics.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2019/03/Dastgeer-Shaikh-120x120.jpg\n",
      "presenter_linkedin None\n",
      "presenter_title  PhD\n",
      "presenter_name Dastgeer Shaikh\n",
      "presenter_orgs [Organization  iCIMS]\n",
      "presenter_positions [Position Senior Data Scientist ]\n",
      "presenter_bio \n",
      "Christopher Maier is a data scientist at iCIMS, a leading provider of recruitment software solutions for global enterprise companies. Maier plays an instrumental role in producing data insights for thought leadership content for iCIMS, including the development of the iCIMS Monthly Hiring Indicator, which measures job openings and hires. He built the indicator, which provides an early and all-encompassing view of the U.S. labor market, drawing from iCIMS’ database of more than 75 million applications and 3 million jobs a year.\n",
      "Maier has additional experience in the medical device and pharmaceutical industries, solving business problems as a statistician/statistical modeler at companies including Roche Molecular Systems and The Janssen Pharmaceutical Companies of Johnson & Johnson. He holds a master’s degree in Applied Statistics from the New Jersey Institute of Technology.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2019/04/Christopher-Maier-120x120.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/christopher-maier-asq-cssgb-922a1495/\n",
      "presenter_title None\n",
      "presenter_name Christopher Maier\n",
      "presenter_orgs [Organization  iCIMS]\n",
      "presenter_positions [Position Data scientist ]\n",
      "categories [Category Workshops, Category Research Bridge, Category  Machine Learning, Category  Beginner-Intermediate]\n",
      "\n",
      "title Deciphering the Black Box:  Latest Tools and Techniques for Interpretability\n",
      "day may-1st\n",
      "time 09:00\n",
      "datetime 2019-05-01 09:00:00\n",
      "excerpt This workshop shows how interpretability tools can give you not only more confidence in a model, but also help to improve model performance. Through this interactive workshop, you will learn how to better understand the models you build, along with the latest techniques and many tricks of the trade around interpretability. The workshop will largely focus on interpretability techniques, such as feature importance, partial dependence, and explanation approaches, such as LIME and Shap. \n",
      "The workshop will demonstrate interpretability techniques with notebooks, some in R and some in Python. Along the way, workshop will consider issues like spurious correlation, random effects, multicollinearity, reproducibility, and other issues that may affect model interpretation and performance. To illustrate the points, the workshop will use easy to understand examples and references to open source tools to illustrate the techniques. \n",
      "presenter_bio \n",
      "Rajiv Shah is a data scientist at DataRobot, where his primary focus is helping customers improve their ability to make and implement predictions. Previously, Rajiv has been part of data science teams at Caterpillar and State Farm. He has worked on a variety of projects from a wide ranging set of areas including supply chain, sensor data, acturial ratings, and security projects. He has a PhD from the University of Illinois at Urbana-Champaign.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2017/09/Rajiv-Shah.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/rcshah/\n",
      "presenter_title  PhD\n",
      "presenter_name Rajiv Shah\n",
      "presenter_orgs [Organization  DataRobot]\n",
      "presenter_positions [Position Data Scientist ]\n",
      "categories [Category Workshop, Category Machine Learning, Category Beginner-Intermediate]\n",
      "\n",
      "title Modeling Volatility Trading Using Econometrics and Machine Learning in Python\n",
      "day april-30th\n",
      "time 09:00\n",
      "datetime 2019-04-30 09:00:00\n",
      "excerpt How can market volatility be predicted, and what are the differences between heuristic models, econometric models and data science/machine learning models? This workshop provides lessons learned from doing econometric modeling in finance distilled into a training course with example project that compares the performance of turbulence, GARCH and blender algorithms. Particular focus on framing the problem and use the right tools for volatility modeling. Aimed at entry level finance quants who want a refresher on Python techniques or non-finance quants looking to make the leap into financial modeling.\n",
      "presenter_bio \n",
      "Stephen Lawrence is the Head of Investment Management Fintech Data Science at The Vanguard Group. He oversees the integration of new structured and unstructured data sources into the investment process, leveraging a blend of NLP and predictive analytics. Prior to joining Vanguard, Dr. Lawrence was Head of Quantextual Research at State Street Bank where he lead a machine learning product team. Prior to that he led FX and Macro flow research for State Street Global Markets. Stephen holds a B.A. in Mathematics from the University of Cambridge and a Ph.D. in Finance from Boston College. He is also a TED speaker with a 2015 talk titled “The future of reading: it’s fast”.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2019/02/Stephen-Lawrence-120x120.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/stephenlawrence/\n",
      "presenter_title  PhD\n",
      "presenter_name Stephen Lawrence\n",
      "presenter_orgs [Organization  Vanguard]\n",
      "presenter_positions [Position Head of Investment Management Fintech Data Science ]\n",
      "presenter_bio \n",
      "Coming soon!\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2019/02/Eunice-Hameyie-Sanon-120x120.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/ehameyie/\n",
      "presenter_title None\n",
      "presenter_name Eunice Hameyie-Sanon\n",
      "presenter_orgs [Organization  Vanguard]\n",
      "presenter_positions [Position Sr. Data Scientist - Investment Management Fintech Strategies ]\n",
      "categories [Category Training, Category  Machine Learning, Category  Beginner – Intermediate]\n",
      "\n",
      "title Beyond Deep Learning – Differentiable Programming with Flux\n",
      "day may-1st\n",
      "time 09:00\n",
      "datetime 2019-05-01 09:00:00\n",
      "excerpt Deep learning is a rapidly evolving field, and models are increasingly complex. Recently, researchers have begun to explore \"differentiable programming\", a powerful way to combine neural networks with traditional programming. Differentiable programs may include control flow, functions and data structures, and can even incorporate ray tracers, simulations and scientific models, giving us even unprecedented power to find subtle patterns in our data.\n",
      "\n",
      "This workshop will show you how this technique, and particularly Flux – a state-of-the-art deep learning library – is impacting the machine learning world. We will show you how Flux makes it easy to create traditional deep learning models, and explain how the flexibility of the Julia language allows complex physical models can be optimised by the same architecture. We'll outline important recent work and show how Flux allows us to easily combine neural networks with tools like differential equations solvers.\n",
      "presenter_bio \n",
      "Jeff is one of the creators of Julia, co-founding the project at MIT in 2009 and eventually receiving a Ph.D. related to the language in 2015. He continues to work on the compiler and system internals, while also working to expand Julia’s commercial reach as a co-founder of Julia Computing, Inc.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2019/04/Jeff-Bezanson-120x120.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/jeffbezanson\n",
      "presenter_title  PhD\n",
      "presenter_name Jeff Bezanson\n",
      "presenter_orgs [Organization  Julia Computing, Organization  Inc.]\n",
      "presenter_positions [Position Co-creator of the Julia language, Position  Co-founder & CTO ]\n",
      "categories [Category Workshops, Category Open Source Data Science, Category Deep Learning, Category Intermediate-Advanced]\n",
      "\n",
      "title Hierarchal And Mixed-effect models in R\n",
      "day may-1st\n",
      "time 09:00\n",
      "datetime 2019-05-01 09:00:00\n",
      "excerpt Data can be nested or have a hierarchal structure. For example, cities exist within states or students attend the same school. However, what can be done to capture this structure? If this group structure is ignored, important group-level variability and structure can be lost. Conversely, aggregating data at a group-level can cause important individual-level variability to be lost. \n",
      "One method for dealing with this structure is to model it. Mixed-effect, or hierarchical, models are a method for doing just this. This course will provide an introduction to mixed-effect models. Next, the course will show how to use mixed-effect models in R using the lme4 package using the lmer() and glmer() functions. Last, the course will describe how hierarchal models can be used to predict new groups.\n",
      "Example datasets from USGS researchers will be used to illustrate how these models may be applied to environmental problems. First, a linear mixed-effect model will be used to explore how adult lamprey densities relate to the amount of DNA adults shed. Second, a generalized linear mixed-effect model will be used to examine the probability of detecting DNA from different densities of juveniles. Last, the course will present a case study of how hierarchal models may be used to predict missing groups using bighead and silver carp data. \n",
      "Prerequisites: \n",
      "Experience with linear models and generalized linear models in R\n",
      "Basic familiarity with R and manipulating and plotting data with the Tidyverse \n",
      "\n",
      "Learning Outcomes:\n",
      "- Understand basics of mixed-effect models\n",
      "- Know how to use lme4's `lmer()` and `glmer()` functions\n",
      "- Awareness of advanced methods\n",
      "presenter_bio \n",
      "Richard helps people to experience and understand their increasingly numerical world. As a Quantitive Ecologist with the USGS, he develops new quantitative methods for monitoring and guiding the control invasive species. He also functions as a consulting statistician within USGS and helps other scientists analyze and understand their data. He has worked on diverse datasets ranging from continent wide species distributions to examining pesticides in playa wetlands. After hours, he teaches SCUBA Diving as a NAUI Instructor.\n",
      "He earned a PhD from Texas Tech where he developed Bayesian models to understand how pesticides impact population dynamics. He has been a user of R since 2007.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2019/04/Richard-Erickson-120x120.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/raerickson\n",
      "presenter_title  PhD\n",
      "presenter_name Richard Erickson\n",
      "presenter_orgs [Organization  U.S. Geological Survey (USGS)]\n",
      "presenter_positions [Position Research Quantitative Ecologist ]\n",
      "categories [Category Training, Category Open Source Data Science, Category Beginner]\n",
      "\n",
      "title Time Series Analysis: From Introduction to Advanced Topics\n",
      "day may-1st\n",
      "time 09:00\n",
      "datetime 2019-05-01 09:00:00\n",
      "excerpt  \n",
      "Time series analysis is both a fascinating subject to study and an important set of techniques that enjoy a wide range of applications in industry, government, and academic settings. Use cases range from inventory management, capacity planning, marketing strategy design, capital budgeting, pricing, macroeconomic forecasting, and supply chain forecasting.\n",
      "A common aspect to all of these applications is the use of forecasting, and time series forecasting requires time series data that is ubiquitous nowadays: weekly initial unemployment claims, product-level hourly sales, tick-level stock prices, daily term structure of interest rates, quarterly company earnings, daily number of steps taken recorded by a wearable, machine performance measurements recorded by sensors, and key performance indicators of business functions, just to name a few.\n",
      "This workshop teaches the application of two important classes of time series statistical models (Autoregressive Integrated Moving Average Model and Vector Autoregressive Model) and an important set of neural network-based algorithms (Recurrent neural network) in time series forecasting. The attendees will learn the mathematical formulation, python implementation, the advantages, and disadvantages of when using these techniques in time series analysis. Jupyter notebooks with examples and sample codes will be provided for attendees to follow along and experiment with these techniques…\n",
      "\n",
      "presenter_bio \n",
      "Jeffrey is the Chief Data Scientist at AllianceBernstein, a global investment firm managing over $500 billions. He is responsible for building and leading the data science group, partnering with investment professionals to create investment signals using data science, and collaborating with sales and marketing teams to analyze clients. Graduated with a Ph.D. in economics from the University of Pennsylvania, he has also taught statistics, econometrics, and machine learning courses at UC Berkeley, Cornell, NYU, the University of Pennsylvania, and Virginia Tech. Previously, Jeffrey held advanced analytic positions at Silicon Valley Data Science, Charles Schwab Corporation, KPMG, and Moody’s Analytics.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2016/04/jeffrey_800_new-e1518013657749.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/jeffreyyau/\n",
      "presenter_title  PhD\n",
      "presenter_name Jeffrey Yau\n",
      "presenter_orgs [Organization  AllianceBernstein]\n",
      "presenter_positions [Position Chief Data Scientist ]\n",
      "categories [Category Training, Category  Machine Learning, Category  Deep Learning]\n",
      "\n",
      "title Good, Fast, Cheap: How to do Data Science with Missing Data\n",
      "day april-30th\n",
      "time 09:00\n",
      "datetime 2019-04-30 09:00:00\n",
      "excerpt If you've never heard of the \"good, fast, cheap\" dilemma, it goes something like this: You can have something good and fast, but it won't be cheap. You can have something good and cheap, but it won't be fast. You can have something fast and cheap, but it won't be good. In short, you can pick two of the three but you can't have all three.\n",
      "\n",
      "If you've done a data science problem before, I can all but guarantee that you've run into missing data. How do we handle it? Well, we can avoid, ignore, or try to account for missing data. The problem is, none of these strategies are good, fast, *and* cheap.\n",
      "\n",
      "We'll start by visualizing missing data and identify the three different types of missing data, which will allow us to see how they affect whether we should avoid, ignore, or account for the missing data. We will walk through the advantages and disadvantages of each approach as well as how to visualize and implement each approach. We'll wrap up with practical tips for working with missing data and recommendations for integrating it with your workflow!\n",
      "presenter_bio \n",
      "Matt currently leads instruction for GA’s Data Science Immersive in Washington, D.C. and most enjoys bridging the gap between theoretical statistics and real-world insights. Matt is a recovering politico, having worked as a data scientist for a political consulting firm through the 2016 election. Prior to his work in politics, he earned his Master’s degree in statistics from The Ohio State University. Matt is passionate about making data science more accessible and putting the revolutionary power of machine learning into the hands of as many people as possible. When he isn’t teaching, he’s thinking about how to be a better teacher, falling asleep to Netflix, and/or cuddling with his pug.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2018/03/Matthew-Brems.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/matthewbrems/\n",
      "presenter_title None\n",
      "presenter_name Matt Brems\n",
      "presenter_orgs [Organization  General Assembly]\n",
      "presenter_positions [Position Global Lead Data Science Instructor ]\n",
      "categories [Category Training, Category Data Visualization, Category Machine Learning, Category Beginner-Intermediate-Advanced]\n",
      "\n",
      "title Real-ish Time Predictive Analytics with Spark Structured Streaming\n",
      "day may-1st\n",
      "time 09:00\n",
      "datetime 2019-05-01 09:00:00\n",
      "excerpt  \n",
      "In this workshop we will dive deep into what it takes to build and deliver an always-on “real-ish time” predictive analytics pipeline with Spark Structured Streaming.\n",
      "The core focus of the workshop material will be on how to solve a common complex problem in which we have no labeled data in an unbounded timeseries dataset and need to understand the substructure of said chaos in order to apply common supervised and statistical modeling techniques to our data in a streaming fashion.\n",
      "The example problem for the workshop will come from the telecommunications space but the skills you will leave with can be applied to almost any domain as long as you sprinkle in a little creativity and inject a bit of domain knowledge.\n",
      "Skills Aquired:\n",
      "1. Structured Streaming experience with Apace Spark.\n",
      "2. Understand how to use supervised modeling techniques on unsupervised data (caveat: requires some domain knowledge and the good ol human touch).\n",
      "3. Have fun for 90 minutes…\n",
      "\n",
      "presenter_bio \n",
      "Scott Haines is a full stack engineer with a current focus on real-time, highly available, trust-worthy analytics systems. He is currently working at Twilio (as Principal Engineer / Tech Lead of the Voice Insights team) where he helped drive spark adoption and streaming pipeline architectures. Prior to Twilio, he worked writing the backend java API’s for Yahoo Games, as well as the real-time game ranking/ratings engine (built on Storm) to provide personalized recommendations and page views for 10 million customers. He finished his tenure at Yahoo working for Flurry Analytics where he wrote the alerts/notifications system for mobile.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2019/01/Scott-Haines-120x120.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/scotthaines/\n",
      "presenter_title None\n",
      "presenter_name Scott Haines\n",
      "presenter_orgs [Organization  Twilio]\n",
      "presenter_positions [Position Principal Software Engineer ]\n",
      "categories [Category Workshop, Category  AI for Engineers, Category  Big Data, Category  Intermediate]\n",
      "\n",
      "title Introduction to Reinforcement Learning\n",
      "day may-1st\n",
      "time 09:00\n",
      "datetime 2019-05-01 09:00:00\n",
      "excerpt Reinforcement Learning recently progressed greatly in industry as one of the best techniques for sequential decision making and control policies.\n",
      "\n",
      "Deep Mind used RL to greatly reduce energy consumption in Google's data centre. It has being used to do text summarisation, autonomous driving, dialog systems, media advertisement and in finance by JPMorgan Chase. We are at the very beginning of the adoption of these algorithms as systems are required to operate more and more autonomously.\n",
      "In this workshop we will explore Reinforcement Learning, starting from its fundamentals and ending creating our own algorithms.\n",
      "\n",
      "We will use OpenAI gym to try our RL algorithms. OpenAI is a non profit organisation that want committed to open source all their research on Artificial Intelligence. To foster innovation OpenAI crated a virtual environment, OpenAi gym, where it's easy to test Reinforcement Learning algorithms.\n",
      "\n",
      "In particular we will start with some popular techniques like Multi Armed Bandit, going thought Markov Decision Processes and Dynamic Programming.\n",
      "presenter_bio \n",
      "Leonardo De Marchi holds a Master in Artificial intelligence and has worked as a Data Scientist in the sport world, with clients such as New York Knicks and Manchester United, and with large social networks, like Justgiving.\n",
      "He now works as Lead Data Scientist in Badoo, the largest dating site with over 360 million users, he is also the lead instructor at ideai.io, a company specialized in Deep Learning and Machine Learning training and a contractor for the European Commission.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2018/09/Leonardo-De-Marchi-120x120.jpg\n",
      "presenter_linkedin https://uk.linkedin.com/in/leonardo-de-marchi\n",
      "presenter_title None\n",
      "presenter_name Leonardo De Marchi\n",
      "presenter_orgs [Organization  Badoo]\n",
      "presenter_positions [Position Head of Data Science , Position  Analytics ]\n",
      "categories [Category Training, Category Deep Learning, Category Open Source Data Science, Category Beginner-Intermediate-Advanced]\n",
      "\n",
      "title Introduction to Deep Learning for Engineers\n",
      "day may-1st\n",
      "time 09:00\n",
      "datetime 2019-05-01 09:00:00\n",
      "excerpt We will build and tweak several vision classifiers together starting with perceptrons and building up to transfer learning and convolutional neural networks. We will investigate practical implications of tweaking loss functions, gradient descent algorithms, network architectures, data normalization, data augmentation and so on. This class is super hands on and practical and requires no math or experience with deep learning.\n",
      "presenter_bio \n",
      "Lukas Biewald is a co-founder and CEO of Weights and Biases which builds performance and visualization tools for machine learning teams and practitioners. Lukas also founded Figure Eight (formerly CrowdFlower) — a human in the loop platform transforms unstructured text, image, audio, and video data into customized high quality training data. — which he co-founded in December 2007 with Chris Van Pelt. Prior to co-founding Weights and Biases and CrowdFlower, Biewald was a Senior Scientist and Manager within the Ranking and Management Team at Powerset, a natural language search technology company later acquired by Microsoft. From 2005 to 2006, Lukas also led the Search Relevance Team for Yahoo! Japan.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2017/05/Lukas-Biewald.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/lbiewald\n",
      "presenter_title None\n",
      "presenter_name Lukas Biewald\n",
      "presenter_orgs [Organization  Weights & Biases]\n",
      "presenter_positions [Position Founder ]\n",
      "presenter_bio \n",
      "Chris Van Pelt is a co-founder of Weights and Biases which builds performance and visualization tools for machine learning teams and practitioners. Chris also founded Figure Eight (formerly CrowdFlower) — a human in the loop platform transforms unstructured text, image, audio, and video data into customized high quality training data. — which he co-founded in December 2007 with Lukas Biewald.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2019/03/Chris-Van-Pelt-120x120.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/chrisvanpelt/\n",
      "presenter_title None\n",
      "presenter_name Chris Van Pelt\n",
      "presenter_orgs [Organization  Weights & Biases]\n",
      "presenter_positions [Position Co-founder ]\n",
      "presenter_bio \n",
      "Stacey Svetlichnaya is deep learning engineer at Weights & Biases in San Francisco, CA, helping develop effective tools and patterns for deep learning. Previously a senior research engineer with Yahoo Vision & Machine Learning, working on image aesthetic quality and style classification, object recognition, photo caption generation, and emoji modeling. She has worked extensively on Flickr image search and data pipelines, as well as automating content discovery and recommendation. Prior to Flickr, she helped build a visual similarity search engine with LookFlow, which Yahoo acquired in 2013. Stacey holds a BS ‘11 and MS ’12 in Symbolic Systems from Stanford University.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2019/03/Stacey-Svetlichnaya-120x120.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/stacey-svetlichnaya-3761552a/\n",
      "presenter_title None\n",
      "presenter_name Stacey Svetlichnaya\n",
      "presenter_orgs [Organization  Weights & Biases]\n",
      "presenter_positions [Position Deep Learning Engineer ]\n",
      "categories [Category Training, Category Kickstarter, Category Deep Learning, Category Intermediate-Advanced]\n",
      "\n",
      "title Hands-on introduction to LSTMs in Keras/TensorFlow\n",
      "day april-30th\n",
      "time 09:00\n",
      "datetime 2019-04-30 09:00:00\n",
      "excerpt This is a very hands on introduction to LSTMs in Keras and TensorFlow. We will build a language classifier, generator and a translating sequence to sequence model. We will talk about debugging models and explore various related architectures like GRUs, Bidirectional LSTMs, etc. to see how well they work.\n",
      "presenter_bio \n",
      "Lukas Biewald is a co-founder and CEO of Weights and Biases which builds performance and visualization tools for machine learning teams and practitioners. Lukas also founded Figure Eight (formerly CrowdFlower) — a human in the loop platform transforms unstructured text, image, audio, and video data into customized high quality training data. — which he co-founded in December 2007 with Chris Van Pelt. Prior to co-founding Weights and Biases and CrowdFlower, Biewald was a Senior Scientist and Manager within the Ranking and Management Team at Powerset, a natural language search technology company later acquired by Microsoft. From 2005 to 2006, Lukas also led the Search Relevance Team for Yahoo! Japan.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2017/05/Lukas-Biewald.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/lbiewald\n",
      "presenter_title None\n",
      "presenter_name Lukas Biewald\n",
      "presenter_orgs [Organization  Weights & Biases]\n",
      "presenter_positions [Position Founder ]\n",
      "presenter_bio \n",
      "Chris Van Pelt is a co-founder of Weights and Biases which builds performance and visualization tools for machine learning teams and practitioners. Chris also founded Figure Eight (formerly CrowdFlower) — a human in the loop platform transforms unstructured text, image, audio, and video data into customized high quality training data. — which he co-founded in December 2007 with Lukas Biewald.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2019/03/Chris-Van-Pelt-120x120.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/chrisvanpelt/\n",
      "presenter_title None\n",
      "presenter_name Chris Van Pelt\n",
      "presenter_orgs [Organization  Weights & Biases]\n",
      "presenter_positions [Position Co-founder ]\n",
      "presenter_bio \n",
      "Stacey Svetlichnaya is deep learning engineer at Weights & Biases in San Francisco, CA, helping develop effective tools and patterns for deep learning. Previously a senior research engineer with Yahoo Vision & Machine Learning, working on image aesthetic quality and style classification, object recognition, photo caption generation, and emoji modeling. She has worked extensively on Flickr image search and data pipelines, as well as automating content discovery and recommendation. Prior to Flickr, she helped build a visual similarity search engine with LookFlow, which Yahoo acquired in 2013. Stacey holds a BS ‘11 and MS ’12 in Symbolic Systems from Stanford University.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2019/03/Stacey-Svetlichnaya-120x120.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/stacey-svetlichnaya-3761552a/\n",
      "presenter_title None\n",
      "presenter_name Stacey Svetlichnaya\n",
      "presenter_orgs [Organization  Weights & Biases]\n",
      "presenter_positions [Position Deep Learning Engineer ]\n",
      "categories [Category Training, Category Kickstarter, Category Deep Learning, Category Intermediate-Advanced]\n",
      "\n",
      "title A Deeper Stack For Deep Learning: Adding Visualisations And Data Abstractions to Your Workflow\n",
      "day april-30th\n",
      "time 09:00\n",
      "datetime 2019-04-30 09:00:00\n",
      "excerpt In this training session I introduce a new layer of Python software, called ConX, which sits on top of Keras, which sits on a backend (like TensorFlow.) Do we really need a deeper stack of software for deep learning? Backends, like TensorFlow, can be thought of as \"assembly language\" for deep learning. Keras helps, but is more like \"C++\" for deep learning. ConX is designed to be \"Python\" for deep learning. So, yes, this layer is needed.\n",
      "\n",
      "ConX is a carefully designed library that includes tools for network, weight, and activation visualizations; data and network abstractions; and an intuitive interactive and programming interface. Especially developed for the Jupyter notebook, ConX enhances the workflow of designing and training artificial neural networks by providing interactive visual feedback early in the process, and reducing cognitive load in developing complex networks. \n",
      "\n",
      "This session will start small and move to advanced recurrent networks for images, text, and other data. Participants are encouraged to have samples of their own data so that they can explore a real and meaningful project.\n",
      "\n",
      "A basic understanding of Python and a laptop is all that is required. Many example deep learning models will be provided in the form of Jupyter notebooks.\n",
      "\n",
      "Documentation: https://conx.readthedocs.io/en/latest/\n",
      "\n",
      "\n",
      "presenter_bio \n",
      "Doug Blank is now a Senior Software Engineer at Comet.ML, a start-up in New York City. Comet.ML helps data scientists and engineers track, manage, replicate, and analyze machine learning experiments.\n",
      "Doug was a professor of Computer Science for 18 years at Bryn Mawr College, a small, all-women’s liberal arts college outside of Philadelphia. He has been working on artificial neural networks for almost 30 years. His focus has been on creating models to make analogies, and for use with robot control systems. He is one of the core developers of ConX.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2018/09/Douglas_Blank-120x120.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/douglasblank/\n",
      "presenter_title  PhD\n",
      "presenter_name Douglas Blank\n",
      "presenter_orgs [Organization  Comet.ML]\n",
      "presenter_positions [Position Senior Software Engineer ]\n",
      "categories [Category Training, Category  Open Source Data Science, Category  Deep Learning, Category  Beginner-Intermediate-Advanced]\n",
      "\n",
      "title Machine Learning in R Part I\n",
      "day april-30th\n",
      "time 09:00\n",
      "datetime 2019-04-30 09:00:00\n",
      "excerpt Modern statistics has become almost synonymous with machine learning, a collection of techniques that utilize today's incredible computing power. This two-part course focuses on the available methods for implementing machine learning algorithms in R, and will examine some of the underlying theory behind the curtain. We start with the foundation of it all, the linear model and its generalization, the glm. We look how to assess model quality with traditional measures and cross-validation and visualize models with coefficient plots. Next we turn to penalized regression with the Elastic Net. After that we turn to Boosted Decision Trees utilizing xgboost. Attendees should have a good understanding of linear models and classification and should have R and RStudio installed, along with the `glmnet`, `xgboost`, `boot`, `ggplot2`, `UsingR` and `coefplot` packages.\n",
      "\n",
      "Linear Models\n",
      "Learn about the best fit line\n",
      "Understand the formula interface in R\n",
      "Understand the design matrix\n",
      "Fit Models with `lm`\n",
      "Visualize the coefficients with `coefplot`\n",
      "Make predictions on new data\n",
      "\n",
      "Generalized Linear Models\n",
      "Learn about Logistic Regression for classification\n",
      "Learn about Poisson Regression for count data\n",
      "Fit models with `glm`\n",
      "Visualize the coefficients with `coefplot`\n",
      "\n",
      "Model Assessment\n",
      "Compare models\n",
      "`AIC`\n",
      "`BIC`\n",
      "\n",
      "Cross-validation\n",
      "Learn the reasoning and process behind cross-validation\n",
      "\n",
      "Elastic Net\n",
      "Learn about penalized regression with the Lasso and Ridge\n",
      "Fit models with `glmnet`\n",
      "Understand the coefficient path\n",
      "View coefficients with `coefplot`\n",
      "\n",
      "Boosted Decision Trees\n",
      "Learn how to make classifications (and regression) using recursive partitioning\n",
      "Fit models with `xgboost`\n",
      "Make compelling visualizations with `DiagrammeR`\n",
      "presenter_bio \n",
      "Jared Lander is the Chief Data Scientist of Lander Analytics a data science consultancy based in New York City, the Organizer of the New York Open Statistical Programming Meetup and the New York R Conference and an Adjunct Professor of Statistics at Columbia University. With a masters from Columbia University in statistics and a bachelors from Muhlenberg College in mathematics, he has experience in both academic research and industry. His work for both large and small organizations ranges from music and fund raising to finance and humanitarian relief efforts.\n",
      "He specializes in data management, multilevel models, machine learning, generalized linear models, data management and statistical computing. He is the author of R for Everyone: Advanced Analytics and Graphics, a book about R Programming geared toward Data Scientists and Non-Statisticians alike and is creating a course on glmnet with DataCamp.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2017/05/Jared-Lander.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/jaredlander/\n",
      "presenter_title None\n",
      "presenter_name Jared Lander\n",
      "presenter_orgs [Organization  Columbia University]\n",
      "presenter_positions [Position Author, Position  R Programming Expert, Position  Statistics Professor  ]\n",
      "categories [Category Training, Category Kickstarter, Category Machine Learning, Category Beginner-Intermediate-Advanced]\n",
      "\n",
      "title TensorFlow 2.0 and Keras: What’s New, What’s Shared, What’s Different\n",
      "day may-1st\n",
      "time 09:00\n",
      "datetime 2019-05-01 09:00:00\n",
      "excerpt You have been using keras for deep learning models and are ready to bring your skills to the next level. In this workshop we will explore the use of pre-trained networks for image classification, transfer learning to adapt a pre-trained network to your use case, multi gpu training, data augmentation, keras callbacks and support for different kernels\n",
      "presenter_bio \n",
      "Francesco Mosconi. Ph.D. in Physics and CEO & Chief Data Scientist at Catalit Data Science. With Catalit Francesco helps Fortune 500 companies to up-skill in Machine Learning and Deep Learning through intensive training programs and strategic advisory. Author of the Zero to Deep Learning book and bootcamp, he is also an instructor at Udemy and Cloud Academy. Formerly co-founder and Chief Data Officer at Spire, a YC-backed company that invented the first consumer wearable device capable of continuously tracking respiration and physical activity. Machine Learning and python expert. Also served as Data Science lead instructor at General Assembly and The Data incubator.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2017/05/Francesco-Mosconi.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/framosconis/\n",
      "presenter_title  PhD\n",
      "presenter_name Francesco Mosconi\n",
      "presenter_orgs [Organization  Catalit]\n",
      "presenter_positions [Position Data Scientist ]\n",
      "categories [Category Training, Category Deep Learning, Category Open Source Data Science, Category Advanced]\n",
      "\n",
      "title Engineering a Performant Machine Learning Pipeline: From Dask to Kubeflow\n",
      "day april-30th\n",
      "time 09:00\n",
      "datetime 2019-04-30 09:00:00\n",
      "excerpt The lifecycle of any machine learning model, regular or deep, consists of (a) the pre-processing/transformation/augmenting of data (b) the training of the model with different hyper-parameter values/learning rates (c) the computing of results on new data/test sets. Whether you are using transfer learning, or a from-scratch model, this process requires a large amount of computation, management of your experimental process, and the quick perusal of results from your experiment. In this workshop, we will learn how to combine off-the shelf clustering software such as kubernetes and dask, with learning systems such as tensorflow/pytorch/scikit-learn, on cloud infrastructure such as AWS/Google Cloud/Azure to construct a machine-learning system for your data science team. We'll start with an understanding of kubernetes, move onto analysis pipelines in sklearn and dask, finally arriving at kubeflow. Participants should install minikube on their laptops (https://kubernetes.io/docs/tasks/tools/install-minikube/), and create accounts on the Google Cloud.\n",
      "presenter_bio \n",
      "Rahul Dave is a lecturer in Bayesian Statistics and Machine Learning at Harvard University, and consults on the same topics at LxPrior. He holds a Ph.D. from the University of Pennsylvania in Computational Astrophysics, and has programmed device drivers for telescopes, bespoke databases for astrophysical data, and machine learning systems in various fields. His new startup, univ.ai, helps students and companies upgrade the skill and understanding of both their developers and managers for this new AI driven world, by providing both corporate training and consulting.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2018/12/Rahul-Dave-jpg-120x120.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/dr-rahul-dave-0115364/\n",
      "presenter_title None\n",
      "presenter_name Dr. Rahul Dave\n",
      "presenter_orgs [Organization  univ.ai, Organization  lxprior.com , Organization  Harvard University]\n",
      "presenter_positions [Position Chief Scientist ]\n",
      "presenter_bio \n",
      "Richard Kim is the founder and CEO of Markov Lab, an AI startup that explores the application of probabilistic modeling and deep learning in the analysis and prediction of financial data. Richard is a Chartered Financial Analyst (CFA) with years of fundamental equity research experience and academic research in artificial intelligence from MIT. Richard has earned his Master’s in Sciences from Massachusetts Institute of Technology where he authored several papers in computational cognitive models of ethical decision makings for autonomous vehicles, one of which was published in October 2018 issue of Nature, “The Moral Machine experiment.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2019/04/Richard-Kim-120x120.png\n",
      "presenter_linkedin None\n",
      "presenter_title None\n",
      "presenter_name Richard Kim\n",
      "presenter_orgs [Organization  Markov Lab]\n",
      "presenter_positions [Position Founder , Position  CEO ]\n",
      "categories [Category Training, Category  AI for Engineers, Category  Machine Learning, Category  Intermediate-Advanced]\n",
      "\n",
      "title Building Generative Adversarial Networks in Tensorflow and Keras\n",
      "day may-1st\n",
      "time 09:00\n",
      "datetime 2019-05-01 09:00:00\n",
      "excerpt Generative Adversarial Networks are a promising modern application of Deep Learning that allows models to *generate* examples. However, GANs are complex, difficult to tune, and limited to small examples. We will explore recent GAN progress with a model that generates faces conditional on desired features, like 'smiling' and 'bangs'.\n",
      "\n",
      "This workshop is designed for Data Scientists, researchers, and software developers familiar with keras, tensorflow, or similar recent Deep Learning tools. It is expected that most in the audience will be able to build models and begin to train them on a local machine. Such students will not leave the tutorial with fully trained models. While students are not expected to have remote access to a machine configured with CUDA and tensorflow-gpu, the instructor will.\n",
      "After attending, students in the target audience should be able to - Identify and explain the essential components of Generative Adversarial Networks including Deep Convolutional versions. - Modify existing GAN implementations. - Design a GAN for a novel application. - Understand and explain recent improvements in GAN loss functions.\n",
      "presenter_bio \n",
      "Sophie is a Senior Data Scientist at Metis where she is a bootcamp instructor and leads curriculum development. Sophie works in deep learning and data science ethics. Through t4tech she helps provide free trans-centered classes in programming and data science. She holds masters degrees in Electrical and Computer Engineering and Psychology, and her writing has appeared in Information Week. Sophie is passionate about teaching, both in theory and in practice, and about making sure that data science is primarily a tool that is used to improve people’s lives.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2019/02/Sophie-Searcy-1-120x120.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/sophsea/\n",
      "presenter_title None\n",
      "presenter_name Sophie Searcy\n",
      "presenter_orgs [Organization  Metis]\n",
      "presenter_positions [Position Sr. Data Scientist ]\n",
      "categories [Category Training, Category Deep Learning, Category  Open Source Data Science , Category  Intermediate]\n",
      "\n",
      "title Advanced Machine Learning with scikit-learn Part I\n",
      "day may-1st\n",
      "time 09:00\n",
      "datetime 2019-05-01 09:00:00\n",
      "excerpt Scikit-learn is a machine learning library in Python, that has become a valuable tool for many data science practitioners. This training will cover some of the more advanced aspects of scikit-learn, such as building complex machine learning pipelines, advanced model evaluation, feature engineering and working with imbalanced datasets. We will also work with text data using the bag-of-word method for classification.\n",
      "\n",
      "This workshop assumes familiarity with Jupyter notebooks and basics of pandas, matplotlib and numpy. It also assumes some familiarity with the API of scikit-learn and how to do cross-validations and grid-search with scikit-learn.\n",
      "presenter_bio \n",
      "Andreas Mueller received his MS degree in Mathematics (Dipl.-Math.) in 2008 from the Department of Mathematics at the University of Bonn. In 2013, he finalized his PhD thesis at the Institute for Computer Science at the University of Bonn. After working as a machine learning scientist at the Amazon Development Center Germany in Berlin for a year, he joined the Center for Data Science at the New York University in the end of 2014. In his current position as assistant research engineer at the Center for Data Science, he works on open source tools for machine learning and data science. He is one of the core contributors of scikit-learn, a machine learning toolkit widely used in industry and academia, for several years, and has authored and contributed to a number of open source projects related to machine learning.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2015/12/Andreas-Mueller-1.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/andreas-mueller-b370265a/\n",
      "presenter_title  PhD\n",
      "presenter_name Andreas Mueller\n",
      "presenter_orgs [Organization  Columbia Data Science Institute]\n",
      "presenter_positions [Position Author, Position  Research Scientist, Position  Core Contributor of scikit-learn ]\n",
      "presenter_bio \n",
      "Thomas Fan is a Software Developer at Columbia University’s Data Science Institute. He collaborates with the scikit-learn community to develop features, review code, and resolve issues. On his free time, Thomas contributes to skorch, a scikit-learn compatible neural network library that wraps PyTorch.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2019/03/Thomas-Fan-1-120x120.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/thomasjpfan/\n",
      "presenter_title None\n",
      "presenter_name Thomas Fan\n",
      "presenter_orgs [Organization  Columbia Data Science Institute]\n",
      "presenter_positions [Position Software Developer - Machine Learning ]\n",
      "categories [Category Training, Category Kickstarter, Category Machine Learning, Category Beginner-Intermediate-Advanced]\n",
      "\n",
      "title Apache Spark for Fast Data Science (and Fast Python Integration!) at Scale\n",
      "day april-30th\n",
      "time 09:00\n",
      "datetime 2019-04-30 09:00:00\n",
      "excerpt We'll start with the basics of machine learning on Apache Spark: when to use it, how it works, and how it compares to all of your other favorite data science tooling.\n",
      "\n",
      "You'll learn to use Spark (with Python) for statistics, modeling, inference, and model tuning. But you'll also get a peek behind the APIs: see why the pieces are arranged as they are, how to get the most out of the docs, open source ecosystem, third-party libraries, and solutions to common challenges.\n",
      "\n",
      "By lunch, you will understand when, why, and how Spark fits into the data science world, and you'll be comfortable doing your own feature engineering and modeling with Spark.\n",
      "\n",
      "We will then look at some of the newest features in Spark that allow elegant, high performance integration with your favorite Python tooling. We'll discuss distributed scheduling for popular libraries like TensorFlow, as well as fast model inference, traditionally a challenge with Spark. We'll even see how you can integrate Spark with Python+GPU computation on arrays (PyTorch) or dataframes (RapidsAI).\n",
      "\n",
      "By the end of the day, you will be caught up on the latest, easiest, fastest, and most user friendly ways of applying Apache Spark in your job and/or research.\n",
      "presenter_bio \n",
      "Adam Breindel consults and teaches widely on Apache Spark, big data engineering, and machine learning. He supports instructional initiatives and teaches as a senior instructor at Databricks, teaches classes on Apache Spark and on deep learning for O’Reilly, and runs a business helping large firms and startups implement data and ML architectures. Adam’s 20 years of engineering experience include streaming analytics, machine learning systems, and cluster management schedulers for some of the world’s largest banks, along with web, mobile, and embedded device apps for startups. His first full-time job in tech was on a neural-net-based fraud detection system for debit transactions, back in the bad old days when some neural nets were patented (!) and he’s much happier living in the age of amazing open-source data and ML tools today\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2016/06/adam-breindel-e1524931339234.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/adbreind/\n",
      "presenter_title None\n",
      "presenter_name Adam Breindel\n",
      "presenter_orgs None\n",
      "presenter_positions None\n",
      "categories [Category Training, Category Deep Learning, Category Machine Learning, Category Beginner-Intermediate]\n",
      "\n",
      "title Deep Learning From Scratch\n",
      "day may-1st\n",
      "time 11:00\n",
      "datetime 2019-05-01 11:00:00\n",
      "excerpt There are many good tutorials on neural networks out there. While some of them dive deep into the code and show how to implement things, and others explain what is going on via diagrams or math, very few bring all the concepts needed to understand neural networks together, showing diagrams, code, and math side by side. In this tutorial, I’ll present a clear, step-by-step explanation of neural networks, implementing them from scratch in Numpy, while showing both diagrams that explain how they work and the math that explains why they work. We’ll cover normal, feedforward neural networks, convolutional neural networks (also from scratch) as well as recurrent neural networks (time permitting). Finally, we’ll be sure to leave time to translate what we learn into performant, flexible PyTorch code so you can apply what you’ve learned to real-world problems.\n",
      "\n",
      "No background in neural networks is required, but a familiarity with the terminology of supervised learning (e.g. training set vs. testing set, features vs. target) will be helpful.\n",
      "presenter_bio \n",
      "Seth Weidman is a data scientist at Facebook, working on machine learning problems related to their data center operations. Prior to this role, Seth was a Senior Data Scientist at Metis, where he first taught two data science bootcamps in Chicago and then taught for one year as part of Metis’ Corporate Training business. Prior to that, Seth was the first data scientist at Trunk Club in Chicago, where he built their first lead scoring model from scratch and worked on their recommendation systems.\n",
      "In addition to solving real-world ML problems, he loves demystifying concepts at the cutting edge of machine learning, from neural networks to GANs. He is the author of a forthcoming O’Reilly book on neural networks and has spoken on these topics at multiple conferences and Meetups all over the country.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2019/04/Seth-Weidman-120x120.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/sethhweidman/\n",
      "presenter_title None\n",
      "presenter_name Seth Weidman\n",
      "presenter_orgs [Organization  Facebook]\n",
      "presenter_positions [Position Senior Data Scientist ]\n",
      "categories [Category Tutorials, Category Deep Learning, Category Open Source Data Science, Category Beginner-Intermediate]\n",
      "\n",
      "title Building an Open Source Streaming Analytics Solution with Kafka and Druid\n",
      "day may-1st\n",
      "time None\n",
      "datetime 2019-05-01 00:00:00\n",
      "excerpt The maturation and development of open source technologies has made it easier than ever for companies to derive insights from vast quantities of data. In this talk, we will cover how data analytic stacks have evolved from data warehouses, to data lakes, and to more modern streaming analytics stack. We will also discuss building such a stack using Apache Kafka and Apache Druid.\n",
      "\n",
      "Analytics pipelines running purely on Hadoop can suffer from hours of data lag. Initial attempts to solve this problem often lead to inflexible solutions, where the queries must be known ahead of time, or fragile solutions where the integrity of the data cannot be assured. Combining Hadoop with Kafka and Druid can guarantee system availability, maintain data integrity, and support fast and flexible queries.\n",
      "\n",
      "In the described system, Kafka provides a fast message bus and is the delivery point for machine-generated event streams. Kafka streams can be used to manipulated data to load into Druid. Druid provides flexible, highly available, low-latency queries.\n",
      "\n",
      "This talk is based on our real-world experiences building out such a stack for many use cases across many industries in the real world.\n",
      "presenter_bio \n",
      "Fangjin is a co-author of the open source Druid project and a co-founder of Imply, a San Francisco based technology company. Fangjin previously held senior engineering positions at Metamarkets and Cisco. He holds a BASc in Electrical Engineering and a MASc in Computer Engineering from the University of Waterloo, Canada.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2017/08/Fangjin-Yang.jpeg\n",
      "presenter_linkedin https://www.linkedin.com/in/fangjin/\n",
      "presenter_title None\n",
      "presenter_name Fangjin Yang\n",
      "presenter_orgs None\n",
      "presenter_positions None\n",
      "categories [Category Workshop, Category  Open Source Data Science, Category  Big Data, Category  Intermediate]\n",
      "\n",
      "title Explaining XGBoost Models – Tools and Methods\n",
      "day may-1st\n",
      "time 11:00\n",
      "datetime 2019-05-01 11:00:00\n",
      "excerpt There is a widespread belief that the twin modeling goals of prediction and explanation are in conflict.  That is, if one desires superior predictive power, then by definition one must pay a price of having little insight into how the model made its predictions. Conversely, if one desires explanations then one must only use \"\"highly interpretable\"\" methods like linear and logistic regression. However, in reality, this tradeoff is by no means a given.  In fact, methods with high predictive power, when examined properly with sophisticated tooling, can yield practical insights that could never be realized by high bias methods like linear and logistic regression.  Furthermore, the insights gained by carefully examining a model can be used to suggest better features, thereby improving model performance. Thus, the twin goals of prediction and understanding can instead form a virtuous cycle rather than remaining in conflict.\n",
      "\n",
      "In this workshop, we will work hands-on using XGBoost with real-world data sets to demonstrate how to approach data sets with the twin goals of prediction and understanding in a manner such that improvements in one area yield improvements in the other. Using modern tooling such as Individual Conditional Expectation (ICE) plots and SHAP, as well as a sense of curiosity, we will extract powerful insights that could not be gained from simpler methods. In particular, attention will be placed on how to approach a data set with the goal of understanding as well as prediction.\n",
      "presenter_bio \n",
      "Brian Lucena is Principal at Lucena Consulting and a consulting Data Scientist at Agentero. An applied mathematician in every sense, he is passionate about applying modern machine learning techniques to understand the world and act upon it. In previous roles he has served as SVP of Analytics at PCCI, Principal Data Scientist at Clover Health, and Chief Mathematician at Guardian Analytics. He has taught at numerous institutions including UC-Berkeley, Brown, USF, and the Metis Data Science Bootcamp.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2019/02/Brian-Lucena-120x120.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/brianlucena/\n",
      "presenter_title  PhD\n",
      "presenter_name Brian Lucena\n",
      "presenter_orgs [Organization  Agentero]\n",
      "presenter_positions [Position Consulting Data Scientist ]\n",
      "categories [Category Workshops, Category  Machine Learning, Category  Intermediate]\n",
      "\n",
      "title Predictive Models with Explanatory Concepts: A Framework for Extracting Reason Codes from Machine Learning Credit Risk Models While Simultaneously Increasing Predictive Power\n",
      "day may-1st\n",
      "time 11:00\n",
      "datetime 2019-05-01 11:00:00\n",
      "excerpt Lenders are required to transmit relatively few raw consumer credit behavior data values to credit reporting agencies. From the raw data, credit bureaus have derived thousands of predictive attributes. By construction, these derived attributes are highly correlated. Multicollinearity is known to hamper the ability to explain statistical and machine learning models. In general, it is desirable if not required to be able to explain the inner workings of credit risk models. When a modeler attempts to incorporate numerous highly collinear attributes in a statistical model and maximize prediction, the impact of multicollinearity works against explainability. Traditional solutions to this problem include omitting variables with the wrong sign or using factor analysis to collapse the original variables into a new subset of variables prior to estimating model parameters. Both solutions increase the ability to explain the model at the expense of decreasing its predictive power. \n",
      "This paper describes a novel method of utilizing multicollinearity in the data to increase the predictive power of the credit risk model and simultaneously allows reason codes to be extracted from it. We make use of the original attributes, and develop a factor analysis after building the predictive model that allows identification of the concepts that describe reasons credit may be denied. The model is constructed so as to be as predictive as possible using readily available data. Reason codes are extracted from the factors. Eight ways to accomplish this are described. It can be applied to any credit scoring system including traditional logistic regression models and machine learning models.\n",
      "presenter_bio \n",
      "Michael McBurnett is a Distinguished Scientist in the Equifax Data Science Lab. He has 30 years of experience building, deploying, or monetizing mathematical models of human behavior in the credit risk, banking, combination utility, telecommunications, direct marketing, counterinsurgency warfare, intelligence, political, and academic arenas. His professional career has focused on mathematical and statistical modeling, data collection, the invention or identification of new data sources appropriate for particular problems, and data analysis. He is a co-inventor of NeuroDecision®, a regulatory compliant method of producing actionable risk scores with appropriate adverse action codes using neural networks.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2019/04/Michael-McBurnett-120x120.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/michael-mcburnett-39a2591/\n",
      "presenter_title  PhD\n",
      "presenter_name Michael McBurnett\n",
      "presenter_orgs [Organization  Equifax Corporation]\n",
      "presenter_positions [Position Distinguished Scientist ]\n",
      "categories [Category Tutorials, Category Machine Learning, Category Research Bridge, Category Intermediate]\n",
      "\n",
      "title All The Cool Things You Can Do With Postgresql To Next Level Your Data Analysis\n",
      "day may-1st\n",
      "time 11:00\n",
      "datetime 2019-05-01 11:00:00\n",
      "excerpt The intention of this VERY hands on workshop is to get you introduced and playing with some of the great features you never knew about in Postgresql. You know, and probably already love, PostgreSQL as your relational database. We will show you how you can forget about using ElasticSearch, MongoDB, and Redis for a broad array of use cases. We will add in some nice statistical work with R embedded in Postgresql. Finally we will bring this all together using the gold standard in spatial databases, PostGIS. Unless you have a specialized use case, PostgreSQL is the answer. The session will be very hands on with plenty of interactive exercises.\n",
      "presenter_bio \n",
      "Steve is the Developer Relations lead for DigitalGlobe. He goes around and shows off all the great work the DigitalGlobe engineers do. Steve has a Ph.D. in Ecology from University of Connecticut.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2018/09/Steven-Pousty-120x120.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/thesteve0/\n",
      "presenter_title  PhD\n",
      "presenter_name Steven Pousty\n",
      "presenter_orgs [Organization  Crunchy Data]\n",
      "presenter_positions [Position Director of Developer Relations ]\n",
      "categories [Category Workshops, Category  Open Source Data Science, Category  AI for Engineers, Category  Beginner-Intermediate]\n",
      "\n",
      "title Introduction To Building A Distributed Neural Network on Apache Spark With BigDL And Analytics Zoo\n",
      "day april-30th\n",
      "time 14:00\n",
      "datetime 2019-04-30 14:00:00\n",
      "excerpt  \n",
      "Abstract: In this training session you will get hands on experience with developing neural network using Intel BigDL and Analytics Zoo on Apache Spark. You will learn how you can use Spark DataFrames and build deep learning pipelines through implementing some practical examples.\n",
      "Target Audience: AI developers and aspiring data scientists who are Experienced in Python and Spark. Also big data and analytics professionals interested in neural networks\n",
      "\n",
      "Prerequisites: \n",
      "• Experience in Python programming\n",
      "• Entry level knowledge of Apache Spark\n",
      "• Basic knowledge of deep learning and techniques in deep learning\n",
      " \n",
      "Training outline:\n",
      " \n",
      "Introduction to Deep Learning on Spark, BigDL and Analytics Zoo - 25 minutes\n",
      "We will begin with a brief introduction to Apache Spark and the Machine Learning/Deep Learning ecosystem around Spark. Then we will introduce Intel BigDL and Analytics Zoo, two deep learning libraries for Apache Spark. We will go into the architectural details of how distributed training happens in BigDL. We will cover the model training process, including how the model, weights and gradients are distributed, calculated, updated and shared with Apache Spark.\n",
      "\n",
      "Setting Up Sample Environment - 10 minutes\n",
      "The instructors will highlight the major components of our demonstration environment, including the dataset, docker container and example code along with the public location of these resources and how to set them up.\n",
      "\n",
      "Exercise 1 - Quick and simple image recognition use case with BigDL - 45 minutes\n",
      "We will work through a simple image recognition use case that trains a CNN. The goal of this exercise is a simple introduction in to using BigDL with image datasets. Participants will get exposure to:\n",
      "• How to use read images into Spark data frames\n",
      "• Building transformation pipelines for images with Spark\n",
      "• How to train a deep learning model using estimators\n",
      "\n",
      "Exercise 2 - Transfer Learning for Image Classification Models - 45 minutes\n",
      "Participants will get exposure to:\n",
      "• How to build a pipeline in Spark to preprocess images\n",
      "• How to import a model a trained model from other frameworks like TensorFlow\n",
      "• How to implement transfer learning on the imported model with the preprocessed images\n",
      "\n",
      "Quick break: Answer questions or help out anyone who is having trouble - 10 minutes\n",
      "\n",
      "Exercise 3 - Anomaly Detection or Recommendation system with Intel Analytics Zoo - 30 minutes\n",
      "In this exercise we will show participants \n",
      "• How to build an initial pipeline for feature transformation\n",
      "• How to Build a recommendation model in BigDL/Analytics Zoo\n",
      "• How to perform training and inference for this use case\n",
      "\n",
      "Exercise 4 - Model Serving - 15 minutes\n",
      "In this exercise we will show participants to how to build an end to end pipeline and put their model to production. They will get exposure to:\n",
      "• Model serving using POJO API\n",
      "• Integration into web services and streaming services like Kafka for model inference\n",
      "• Distributed model inference\n",
      "\n",
      "Practical Knowledge - Discussion of practical experience using Spark and Hadoop for machine learning and deep learning projects - 15 minutes\n",
      "We will have a discussion on the following topics:\n",
      "• Spark parameters and how to set them: How to allocate the right amount of executors, cores and memory\n",
      "• Performance Monitoring\n",
      "• Tensorboard with BigDL\n",
      "• Collaboration and reproducing experiments with a data science workbench tool.\n",
      "\n",
      "Wrapping up / Questions - 15 minutes\n",
      " \n",
      "\n",
      "presenter_bio \n",
      "Bala Chandrasekaran is a Technical Staff Engineer at Dell Technologies, where he is responsible for building machine learning and deep learning infrastructure solutions. He has over 15 years of experience in the areas of high performance computing, virtualization infrastructure, cloud computing and big data.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2019/01/Bala-Chandrasekaran-120x120.jpeg\n",
      "presenter_linkedin https://www.linkedin.com/in/balacs/\n",
      "presenter_title None\n",
      "presenter_name Bala Chandrasekaran\n",
      "presenter_orgs [Organization  Dell Technologies]\n",
      "presenter_positions [Position Technical Staff ]\n",
      "presenter_bio \n",
      "Andrew is a data scientist at Dell where he explores how machine learning and deep learning techniques are used in spark. His experience includes time series analysis and prediction of pharmaceutical drug sales and usage, real estate valuation using machine learning, and medical data classification using deep learning. Andrew’s interests involve applying machine learning and deep learning to solve new problems and improve old solutions.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2019/03/Andrew-Kipp-120x120.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/andrew-kipp-337b955a/\n",
      "presenter_title None\n",
      "presenter_name Andrew Kipp\n",
      "presenter_orgs [Organization  Dell Technologies]\n",
      "presenter_positions [Position Data Scientist ]\n",
      "presenter_bio \n",
      "Yuhao Yang is a senior software engineer in Intel Big Data team, focusing on deep learning algorithms and applications. His area of focus is distributed deep learning/machine learning and has accumulated rich solution experiences, including fraud detection, recommendation, speech recognition, visual perception etc. He’s also an active contributor of Apache Spark MLlib (GitHub: hhbyyh).\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2019/04/Yuhao-Yang-120x120.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/yuhao-yang-8a150232/\n",
      "presenter_title None\n",
      "presenter_name Yuhao Yang\n",
      "presenter_orgs [Organization  Intel]\n",
      "presenter_positions [Position Senior Software Engineer ]\n",
      "categories [Category Training, Category Open Source Data Science, Category  Deep Learning, Category  Beginner-Intermediate]\n",
      "\n",
      "title Deep Learning Like a Viking: Building Convolutional Neural Networks with Keras\n",
      "day may-1st\n",
      "time 14:00\n",
      "datetime 2019-05-01 14:00:00\n",
      "excerpt The Vikings came from the land of ice and snow, from the midnight sun, where the hot springs flow. In addition to longships and bad attitudes, they had a system of writing that we, in modern times, have dubbed the Younger Futhark (or ᚠᚢᚦᚬᚱᚴ if you're a Viking). These sigils are more commonly called runes and have been mimicked in fantasy literature and role-playing games for decades.\n",
      "\n",
      "Of course, having an alphabet, runic or otherwise, solves lots of problems. But, it also introduces others. The Vikings had the same problem we do today. How were they to get their automated software systems to recognize the hand-carved input of a typical boatman? Of course, they were never able to solve this problem and were instead forced into a life of burning and pillaging. Today, we have deep learning and neural networks and can, fortunately, avoid such a fate.\n",
      "\n",
      "In this session, we are going to build a Convolution Neural Network to recognize hand-written runes from the Younger Futhark. We'll be using Keras to write easy to understand Python code that creates and trains the neural network to do this. We'll wire this up to a web application using Flask and some client-side JavaScript so you can write some runes yourself and see if it recognizes them.\n",
      "\n",
      "When we're done, you'll understand how Convolution Neural Networks work, how to build your own using Python and Keras, and how to make it a part of an application using Flask. Maybe you'll even try seeing what it thinks of the Bluetooth logo?\n",
      "presenter_bio \n",
      "Guy works for DataRobot in Columbus, Ohio as a Developer Evangelist. Combining his decades of experience in writing software with a passion for sharing what he has learned, Guy goes out into developer communities and helps others build great software.\n",
      "Teaching and community have long been a focus for Guy. He is President of the Columbus JavaScript Users Group, an organizer for the Columbus Machine Learners, and has even helped teach programming at a prison in central Ohio.\n",
      "In past lives, Guy has worked as a consultant in a broad range of industries including healthcare, retail, and utilities. He also has spent several years working for a major insurance company in central Ohio. This has given him a broad view of technology application toward business problems.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2015/12/Guy-Royse-120x120.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/groyse/\n",
      "presenter_title None\n",
      "presenter_name Guy Royse\n",
      "presenter_orgs [Organization  Google]\n",
      "presenter_positions [Position Developer Evangelist ]\n",
      "categories [Category Workshops, Category  Deep Learning, Category  AI for Engineers, Category  Beginner]\n",
      "\n",
      "title Machine Learning in R Part II\n",
      "day april-30th\n",
      "time 14:00\n",
      "datetime 2019-04-30 14:00:00\n",
      "excerpt Modern statistics has become almost synonymous with machine learning, a collection of techniques that utilize today's incredible computing power. This two-part course focuses on the available methods for implementing machine learning algorithms in R, and will examine some of the underlying theory behind the curtain. We start with the foundation of it all, the linear model and its generalization, the glm. We look how to assess model quality with traditional measures and cross-validation and visualize models with coefficient plots. Next we turn to penalized regression with the Elastic Net. After that we turn to Boosted Decision Trees utilizing xgboost. Attendees should have a good understanding of linear models and classification and should have R and RStudio installed, along with the `glmnet`, `xgboost`, `boot`, `ggplot2`, `UsingR` and `coefplot` packages.\n",
      "\n",
      "Linear Models\n",
      "Learn about the best fit line\n",
      "Understand the formula interface in R\n",
      "Understand the design matrix\n",
      "Fit Models with `lm`\n",
      "Visualize the coefficients with `coefplot`\n",
      "Make predictions on new data\n",
      "\n",
      "Generalized Linear Models\n",
      "Learn about Logistic Regression for classification\n",
      "Learn about Poisson Regression for count data\n",
      "Fit models with `glm`\n",
      "Visualize the coefficients with `coefplot`\n",
      "\n",
      "Model Assessment\n",
      "Compare models\n",
      "`AIC`\n",
      "`BIC`\n",
      "\n",
      "Cross-validation\n",
      "Learn the reasoning and process behind cross-validation\n",
      "\n",
      "Elastic Net\n",
      "Learn about penalized regression with the Lasso and Ridge\n",
      "Fit models with `glmnet`\n",
      "Understand the coefficient path\n",
      "View coefficients with `coefplot`\n",
      "\n",
      "Boosted Decision Trees\n",
      "Learn how to make classifications (and regression) using recursive partitioning\n",
      "Fit models with `xgboost`\n",
      "Make compelling visualizations with `DiagrammeR`\n",
      "presenter_bio \n",
      "Jared Lander is the Chief Data Scientist of Lander Analytics a data science consultancy based in New York City, the Organizer of the New York Open Statistical Programming Meetup and the New York R Conference and an Adjunct Professor of Statistics at Columbia University. With a masters from Columbia University in statistics and a bachelors from Muhlenberg College in mathematics, he has experience in both academic research and industry. His work for both large and small organizations ranges from music and fund raising to finance and humanitarian relief efforts.\n",
      "He specializes in data management, multilevel models, machine learning, generalized linear models, data management and statistical computing. He is the author of R for Everyone: Advanced Analytics and Graphics, a book about R Programming geared toward Data Scientists and Non-Statisticians alike and is creating a course on glmnet with DataCamp.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2017/05/Jared-Lander.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/jaredlander/\n",
      "presenter_title None\n",
      "presenter_name Jared Lander\n",
      "presenter_orgs [Organization  Columbia University]\n",
      "presenter_positions [Position Author, Position  R Programming Expert, Position  Statistics Professor  ]\n",
      "categories [Category Training, Category Machine Learning, Category Open Source Data Science, Category Beginner-Intermediate-Advanced]\n",
      "\n",
      "title Programming with Data: Python and Pandas\n",
      "day may-1st\n",
      "time 14:00\n",
      "datetime 2019-05-01 14:00:00\n",
      "excerpt Whether in R, MATLAB, Stata, or python, modern data analysis, for many researchers, requires some kind of programming. The preponderance of tools and specialized languages for data analysis suggests that general purpose programming languages like C and Java do not readily address the needs of data scientists; something more is needed.\n",
      "\n",
      "In this workshop, you will learn how to accelerate your data analyses using the Python language and Pandas, a library specifically designed for interactive data analysis. Pandas is a massive library, so we will focus on its core functionality, specifically, loading, filtering, grouping, and transforming data. Having completed this workshop, you will understand the fundamentals of Pandas, be aware of common pitfalls, and be ready to perform your own analyses.\n",
      "presenter_bio \n",
      "Daniel Gerlanc has worked as a data scientist for more than decade and written software professionally for 15 years. He spent 5 years as a quantitative analyst with two Boston hedge funds before starting Enplus Advisors. At Enplus, he works with clients on data science and custom software development with a particular focus on projects requiring an expertise in both areas. He teaches data science and software development at introductory through advanced levels. He has coauthored several open source R packages, published in peer-reviewed journals, and is active in local predictive analytics groups.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2017/11/Daniel-Gerlanc.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/dgerlanc/\n",
      "presenter_title None\n",
      "presenter_name Daniel Gerlanc\n",
      "presenter_orgs [Organization  Enplus Advisors Inc.]\n",
      "presenter_positions [Position President ]\n",
      "categories [Category Training, Category AI for Engineers, Category Open Source Data Science, Category Intermediate-Advanced]\n",
      "\n",
      "title Real-time Anomaly Detection in Surveillance Feeds\n",
      "day may-1st\n",
      "time 14:00\n",
      "datetime 2019-05-01 14:00:00\n",
      "excerpt  \n",
      "Rapid advances in the surveillance infrastructure have enabled us to capture normal and anomalous events at scale, coupled with tremendous progress in computer vision and pattern recognition. However, the issue of timely response to potential threatening situations is still a problem at large. Various challenges such as low quality feeds, occlusion , clutter, lack of training data, adversarial attacks make it extremely hard for the network to achieve the desired and timely accuracy and performance, leading to hazardous situations that could have been potentially avoided. In this paper, we study state of the art approaches to tackle this problem and study their capabilities and limitations. Furthermore we also present the results of several experiments conducted to tackle this challenge from a supervised, unsupervised, generative and reinforcement perspective. We hope to present these results as an enabler for future work in this area…\n",
      "\n",
      "presenter_bio \n",
      "Utkarsh Contractor is the Director of AI at Aisera, where he leads the data science team working on machine learning and artificial intelligence applications in the fields of Natural Language Processing and Vision. He is also pursuing his graduate degree at Stanford University, focussing his research and experiments on computer vision, using CNNs to analyze surveillance scene imagery and footages. Utkarsh has a decade of industry experience in Information Retrieval and Machine Learning working at companies such as LinkedIn and AT&T Labs.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2017/11/Utkarsh-Contractor.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/utkarshc/\n",
      "presenter_title None\n",
      "presenter_name Utkarsh Contractor\n",
      "presenter_orgs [Organization  Aisera Inc.]\n",
      "presenter_positions [Position ML , Position  AI Director ]\n",
      "categories [Category Workshop, Category Machine Learning, Category  Deep Learning, Category  Intermediate]\n",
      "\n",
      "title Machine Learning for Trading\n",
      "day april-30th\n",
      "time 14:00\n",
      "datetime 2019-04-30 14:00:00\n",
      "excerpt The rapid progress in machine learning (ML) and the massive increase in the availability and diversity of data has enabled novel approaches to quantitative investment. It has also increased the demand for the application of data science to develop both discretionary and algorithmic trading strategies. \n",
      "In this workshop, we will cover popular use cases for ML in the investment industry, and how data science and ML fit into the workflow of developing a trading and investment strategy from the identification and combination of alpha factors to strategy backtesting and asset allocation. \n",
      "We will see how a broad range of ML techniques can be used to extract tradeable signals. In particular, the rise of alternative data, i.e. sources beyond market and fundamental data, has created the need to apply deep learning for natural language processing and image classification. We will also take a look at how reinforcement learning can be used to train an agent interactively on market data.  \n",
      "The workshop uses Python and various standard data science and machine learning libraries like pandas, scikit-learn, gensim, spaCy as well as TensorFlow and Keras. The code examples will be presented using jupyter notebooks and are based on my book ‘Machine Learning for Algorithmic Trading’.\n",
      "presenter_bio \n",
      "Stefan is founder, CEO and lead data scientist at Applied AI that provides data strategy consulting, machine learning solutions, as well as executive coaching and training for consumer, healthcare and financial industries. Prior to his current venture, he was co-founder and partner at an international investment firm, building the predictive analytics and investment research practice. Earlier, he was executive at a global fintech company with operations in 15 global markets.\n",
      "A native German, he started his career as advisor to Central Banks in emerging markets and has worked in six languages across Asia, Africa, and Latin America. In 2007, he raised $35m from the Gates Foundation to cofound the Alliance for Financial Inclusion, an international organization for regulators that facilitates the adoption of financial technology to lower barriers to access.\n",
      "Stefan holds a Master in Economics from FU Berlin with a Thesis on Early Warning Systems for Financial Crisis using Machine Learning, an MPA/ID from the Harvard Kennedy School, a CFA Charter, and has published through Harvard and Brookings. He teaches data science at General Assembly, has produced two courses with currently 13,000 students at DataCamp, and is the author of two courses on ‘Mastering Unsupervised Learning’ (forthcoming by Packt).\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2018/04/Stefan-Jansen.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/applied-ai/\n",
      "presenter_title None\n",
      "presenter_name Stefan Jansen\n",
      "presenter_orgs [Organization  Applied Artificial Intelligence, Organization  General Assembly]\n",
      "presenter_positions [Position Founder & Lead Data Scientist, Position  Lead Instructor ]\n",
      "categories [Category Training, Category Open Source Data Science, Category Machine Learning, Category Intermediate-Advanced]\n",
      "\n",
      "title Modern and Old Reinforcement Learning\n",
      "day may-1st\n",
      "time 14:00\n",
      "datetime 2019-05-01 14:00:00\n",
      "excerpt Reinforcement Learning recently progressed greatly in industry as one of the best techniques for sequential decision making and control policies.\n",
      "\n",
      "DeepMind used RL to greatly reduce energy consumption in Google's data centre. It has being used to do text summarisation, autonomous driving, dialog systems, media advertisement and in finance by JPMorgan Chase. We are at the very beginning of the adoption of these algorithms as systems are required to operate more and more autonomously.\n",
      "In this workshop we will explore Reinforcement Learning, starting from its fundamentals and ending creating our own algorithms.\n",
      "\n",
      "We will use OpenAI gym to try our RL algorithms. OpenAI is a non profit organisation that want committed to open source all their research on Artificial Intelligence. To foster innovation OpenAI created a virtual environment, OpenAi gym, where it's easy to test Reinforcement Learning algorithms.\n",
      "\n",
      "In particular we will start with some popular techniques like Multi Armed Bandit, going thought Markov Decision Processes and Dynamic Programming.\n",
      "\n",
      "We then will also explore other RL frameworks and more complex concepts like Policy gradients methods and Deep Reinforcement learning, which recently changed the field of Reinforcement Learning. In particular we will see Actor Critic models and Proximal Policy Optimizations that allowed openai to beat some of the best Dota players. \n",
      "\n",
      "We will also provide the necessary Deep Learning concepts for the course.\n",
      "\n",
      "presenter_bio \n",
      "Leonardo De Marchi holds a Master in Artificial intelligence and has worked as a Data Scientist in the sport world, with clients such as New York Knicks and Manchester United, and with large social networks, like Justgiving.\n",
      "He now works as Lead Data Scientist in Badoo, the largest dating site with over 360 million users, he is also the lead instructor at ideai.io, a company specialized in Deep Learning and Machine Learning training and a contractor for the European Commission.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2018/09/Leonardo-De-Marchi-120x120.jpg\n",
      "presenter_linkedin https://uk.linkedin.com/in/leonardo-de-marchi\n",
      "presenter_title None\n",
      "presenter_name Leonardo De Marchi\n",
      "presenter_orgs [Organization  Badoo]\n",
      "presenter_positions [Position Head of Data Science , Position  Analytics ]\n",
      "categories [Category Training, Category Deep Learning, Category Open Source Data Science, Category Intermediate-Advanced]\n",
      "\n",
      "title Advanced Machine Learning with scikit-learn Part II\n",
      "day may-1st\n",
      "time 14:00\n",
      "datetime 2019-05-01 14:00:00\n",
      "excerpt Scikit-learn is a machine learning library in Python, that has become a valuable tool for many data science practitioners. This training will cover some advanced topics in using scikit-learn, such as how to perform out-of-core learning with scikit-learn and how to speed up parameter search. We'll also cover how to build your own models or feature extraction methods that are compatible with scikit-learn, which is important for feature extraction in many domains. We will see how we can customize scikit-learn even further, using custom methods for cross-validation or model evaluation.\n",
      "\n",
      "This workshop assumes familiarity with Jupyter notebooks and basics of pandas, matplotlib and numpy. It also assumes experience using scikit-learn and familiarity with the API.\n",
      "presenter_bio \n",
      "Andreas Mueller received his MS degree in Mathematics (Dipl.-Math.) in 2008 from the Department of Mathematics at the University of Bonn. In 2013, he finalized his PhD thesis at the Institute for Computer Science at the University of Bonn. After working as a machine learning scientist at the Amazon Development Center Germany in Berlin for a year, he joined the Center for Data Science at the New York University in the end of 2014. In his current position as assistant research engineer at the Center for Data Science, he works on open source tools for machine learning and data science. He is one of the core contributors of scikit-learn, a machine learning toolkit widely used in industry and academia, for several years, and has authored and contributed to a number of open source projects related to machine learning.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2015/12/Andreas-Mueller-1.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/andreas-mueller-b370265a/\n",
      "presenter_title  PhD\n",
      "presenter_name Andreas Mueller\n",
      "presenter_orgs [Organization  Columbia Data Science Institute]\n",
      "presenter_positions [Position Author, Position  Research Scientist, Position  Core Contributor of scikit-learn ]\n",
      "presenter_bio \n",
      "Thomas Fan is a Software Developer at Columbia University’s Data Science Institute. He collaborates with the scikit-learn community to develop features, review code, and resolve issues. On his free time, Thomas contributes to skorch, a scikit-learn compatible neural network library that wraps PyTorch.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2019/03/Thomas-Fan-1-120x120.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/thomasjpfan/\n",
      "presenter_title None\n",
      "presenter_name Thomas Fan\n",
      "presenter_orgs [Organization  Columbia Data Science Institute]\n",
      "presenter_positions [Position Software Developer - Machine Learning ]\n",
      "categories [Category Training, Category Machine Learning, Category Open Source Data Science, Category Beginner-Intermediate-Advanced]\n",
      "\n",
      "title Data Driven Websites: Building Interactive Webpages using Bokeh & Flask\n",
      "day may-1st\n",
      "time 14:00\n",
      "datetime 2019-05-01 14:00:00\n",
      "excerpt Our analyses are only as useful as they are seen and understood, which is why so many good data scientists talk about telling a story with data. You may find yourself in a position where you need to share your work with others publicly without the benefit of expensive dashboarding packages or a glitzy corporate website. With moderate python development skills, you can turn your analyses into impressive public dashboards using Flask and Bokeh.\n",
      "\n",
      "This hands-on workshop will take you from data to website with multiple interactive charts and graphs on a two-page website 100% in python. Templates for the base HTML & CSS will be provided, so you can focus on learning how to build dynamic and interactive visualizations to tell your story. You should have a solid base understanding of python (data types, control flows and functions) but extensive data science experience is not necessary.\n",
      "presenter_bio \n",
      "Bethany is a data scientist, an instructor and a passionate experiential learner. Having started her career as an artist and educator, she is committed data driven story-telling and the appropriate use of graphs.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2019/04/Bethany-Poulin-120x120.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/bethany-poulin-0656995\n",
      "presenter_title None\n",
      "presenter_name Bethany Poulin\n",
      "presenter_orgs [Organization  General Assembly]\n",
      "presenter_positions [Position Data Science Instructor ]\n",
      "categories [Category Training, Category Data Visualization, Category Open Source Data Science, Category Beginner-Intermediate]\n",
      "\n",
      "title An Introduction to PyTorch Fundamentals\n",
      "day may-1st\n",
      "time 14:00\n",
      "datetime 2019-05-01 14:00:00\n",
      "excerpt In this tutorial, we shall have a 30-minute overview of PyTorch followed by a 1 hour tutorial that you shall complete, with the help of the instructor. PyTorch is a python library for numerical computing, automatic differentiation and deep learning, supporting a fast GPU backend for high performance. PyTorch is often used to build neural networks and for gradient-based methods in machine learning.\n",
      "\n",
      "The tutorial will take you through doing operations on PyTorch Tensors, building your own neural networks, training them on small datasets and interpreting the final results. We shall use Google Colab ( https://colab.research.google.com/ ),  a free Cloud notebook service to run the tutorials.\n",
      "Familiarity with Python is required, and familiarity with NumPy helps.\n",
      "presenter_bio \n",
      "Soumith Chintala is a Researcher at Facebook AI Research, where he works on deep learning, reinforcement learning, generative image models, agents for video games and large-scale high-performance deep learning with major contributions to the Torch deep learning framework which is used by the major players in the A.I. Industry. His research on generative models has been quoted to be one of the major advances in A.I. in 2015. His work in the A.I. research and systems community on benchmarking and consolidating systems is well recognized and is often quoted by Intel, Nervana Systems, NVIDIA and other hardware and systems companies as an independent metric. He holds a Masters in CS from NYU, and spent time in Yann LeCun’s NYU lab building deep learning models for pedestrian detection, natural image OCR, depth-images among others.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2019/04/Soumith-Chintala-120x120.jpeg\n",
      "presenter_linkedin https://www.linkedin.com/in/soumith/\n",
      "presenter_title None\n",
      "presenter_name Soumith Chintala\n",
      "presenter_orgs [Organization  Facebook AI Research]\n",
      "presenter_positions [Position Creator of PyTorch ]\n",
      "categories [Category Tutorials, Category Deep Learning, Category Open Source Data Science, Category Beginner-Intermediat]\n",
      "\n",
      "title Beyond Word Embedding: BERT, ElMo and ULMFit NLP models- New Era in Neural Natural Language Processing\n",
      "day may-1st\n",
      "time 14:00\n",
      "datetime 2019-05-01 14:00:00\n",
      "excerpt Big changes are underway in the world of Natural Language Processing (NLP). The long reign of word vectors as NLP’s core representation technique has seen an exciting new line of challengers emerge: ELMo, OpenAI transformer, ULMFiT, Facebook’s PyText, Google’s BERT\n",
      "In this Talk, the audience will get a detailed understanding of the past, present, and future of deep learning in NLP. In addition, readers will also learn some of the current best practices for applying deep learning in NLP. Some topics include: The rise of distributed representations (e.g., word2vec), Convolutional, recurrent, and recursive neural networks, Recent development in unsupervised sentence representation learning, Combining deep learning models with memory-augmenting strategies. Our conceptual understanding of how best to represent words and sentences in a way that best captures underlying meanings and relationships is rapidly evolving. Moreover, the NLP community has been putting forward incredibly powerful components that you can freely download and use in your own models and pipelines. This talk will introduce them to the audience.\n",
      "These works made headlines by demonstrating that pretrained language models can be used to achieve state-of-the-art results on a wide range of NLP tasks. Such methods herald a watershed moment: they may have the same wide-ranging impact on NLP as pretrained ImageNet models had on computer vision.\n",
      "Language understanding is a challenge for computers. Subtle nuances of communication that human toddlers can understand still confuse the most powerful machines. Even though advanced techniques like deep learning can detect and replicate complex language patterns, machine learning models still lack fundamental conceptual understanding of what our words really mean.\n",
      "Understanding context has broken down barriers that had prevented NLP techniques making headway before.\n",
      "\n",
      "Tools: NLTK, Spacy, Google Colab, Pandas, Gensim, PolyGlot, Sci-KitLearn, Glove, Word2Vec, Word Embedding, WEVI, Google Tensorflow Projector, Tensorflow Keras\n",
      "\n",
      "Languages: Python, R, Jupyter Notebook\n",
      "\n",
      "Learning Outcomes:\n",
      "Text mining and the ways of extracting and reading data from some common file types including NLTK corpora \n",
      "Understand some ways of text extraction and cleaning using NLTK. \n",
      "Analyse a sentence structure using a group of words to create phrases and sentences using NLP and the rules of English grammar \n",
      "Explore text classification, vectorization techniques and processing using scikit-learn \n",
      "Build a Machine Learning classifier for text classification \n",
      "Word Embedding\n",
      "Deep Learning Concepts\n",
      "Language Modeling\n",
      "New Era in Pretrained Natural Language Processing language models like Google BERT, Facebook PyText, ELMo etc.\n",
      "presenter_bio \n",
      "Bhairav Mehta is Senior Data Scientist with extensive professional experience and academic background. Bhairav works for Apple Inc. as Sr. Data Scientist.\n",
      "Bhairav Mehta is experienced engineer, business professional and seasoned Statistician / programmer with 19 years of combined progressive experience working on data science in electronics consumer products industry (7 years at Apple Inc.), yield engineering in semiconductor manufacturing (6 years at Qualcomm and MIT Startup) and quality engineering in automotive industry (OEM, Tier2 Suppliers, Ford Motor Company) (3 years). Bhairav founded a start up DataInquest Inc. in 2014 that is specialized in training/consulting in Artificial Intelligence, Machine Learning, Blockchain and Data Science.\n",
      "Bhairav Mehta has MBA from Johnson School of Management at Cornell University, Masters in Computer science from Georgia Tech (Expected 2018), Masters in Statistics from Cornell University, Masters in Industrial Systems Engineering from Rochester Institute of Technology and BS Production Engineering from Mumbai University.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2017/10/Bhairav-Mehta.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/mehtabhairav/\n",
      "presenter_title None\n",
      "presenter_name Bhairav Mehta\n",
      "presenter_orgs [Organization  Apple]\n",
      "presenter_positions [Position Data Science Manager ]\n",
      "categories [Category Training, Category  Open Source Data Science, Category  Deep Learning, Category  Intermediate-Advanced]\n",
      "\n",
      "title Intermediate RMarkdown in Shiny\n",
      "day may-1st\n",
      "time 14:00\n",
      "datetime 2019-05-01 14:00:00\n",
      "excerpt Markdown Primer (45 minutes)Structure Documents with Sections and SubsectionsFormatting TextCreating Ordered and Unordered ListsMaking LinksNumber SectionsInclude Table of Contents\n",
      "Integrate R Code (30 minutes)Insert Code ChunksHide CodeSet Chunk OptionsDraw PlotsSpeed Up Code with Caching\n",
      "Build RMarkdown Slideshows (20 minutes)Understand Slide StructureCreate SectionsSet Background ImagesInclude Speaker NotesOpen Slides in Speaker Mode\n",
      "Develop Flexdashboards (30 minutes)Start with the Flexdashboard LayoutDesign Columns and RowsUse Multiple PagesCreate Social SharingInclude Code\n",
      "Shiny InputsDrop DownsTextRadioChecks\n",
      "Shiny OutputsTextTablesPlots\n",
      "Reactive Expressions\n",
      "HTML WidgetsInteractive PlotsInteractive MapsInteractive Tables\n",
      "Shiny Layouts UI and Server Files User Interface\n",
      "presenter_bio \n",
      "Jared Lander is the Chief Data Scientist of Lander Analytics a data science consultancy based in New York City, the Organizer of the New York Open Statistical Programming Meetup and the New York R Conference and an Adjunct Professor of Statistics at Columbia University. With a masters from Columbia University in statistics and a bachelors from Muhlenberg College in mathematics, he has experience in both academic research and industry. His work for both large and small organizations ranges from music and fund raising to finance and humanitarian relief efforts.\n",
      "He specializes in data management, multilevel models, machine learning, generalized linear models, data management and statistical computing. He is the author of R for Everyone: Advanced Analytics and Graphics, a book about R Programming geared toward Data Scientists and Non-Statisticians alike and is creating a course on glmnet with DataCamp.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2017/05/Jared-Lander.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/jaredlander/\n",
      "presenter_title None\n",
      "presenter_name Jared Lander\n",
      "presenter_orgs [Organization  Columbia University]\n",
      "presenter_positions [Position Author, Position  R Programming Expert, Position  Statistics Professor  ]\n",
      "categories [Category Training, Category Kickstarter, Category Data Visualization, Category Intermediate]\n",
      "\n",
      "title Understanding the PyTorch Framework with Applications to Deep Learning\n",
      "day april-30th\n",
      "time 14:00\n",
      "datetime 2019-04-30 14:00:00\n",
      "excerpt Over the past couple of years, PyTorch has been increasing in popularity in the Deep Learning community. What was initially a tool for Deep Learning researchers has been making headway in industry settings.\n",
      "\n",
      "In this session, we will cover how to create Deep Neural Networks using the PyTorch framework on a variety of examples. The material will range from beginner - understanding what is going on \"under the hood\", coding the layers of our networks, and implementing backpropagation - to more advanced material on RNNs,CNNs, LSTMs, & GANs. \n",
      "\n",
      "Attendees will leave with a better understanding of the PyTorch framework. In particular, how it differs from Keras and Tensorflow. Furthermore, a link to a clean documented GitHub repo with the solutions of the examples covered will be provided.\n",
      "presenter_bio \n",
      "Robert loves to break deep technical concepts down to be as simple as possible, but no simpler.\n",
      "Robert has data science experience in companies both large and small. He is currently Head of Data Science for Podium Education, where he builds models to improve student outcomes, and an Adjunct Professor at Santa Clara University’s Leavey School of Business. Prior to Podium Education, he was a Senior Data Scientist at Metis teaching Data Science and Machine Learning. At Intel, he tackled problems in data center optimization using cluster analysis, enriched market sizing models by implementing sentiment analysis from social media feeds, and improved data-driven decision making in one of the top 5 global supply chains. At Tamr, he built models to unify large amounts of messy data across multiple silos for some of the largest corporations in the world. He earned a PhD in Applied Mathematics from Arizona State University where his research spanned image reconstruction, dynamical systems, mathematical epidemiology and oncology.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2019/04/Robert-Alvarez-120x120.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/robert-l-alvarez/\n",
      "presenter_title  PhD\n",
      "presenter_name Robert Alvarez\n",
      "presenter_orgs [Organization  Podium Education]\n",
      "presenter_positions [Position Head of Data Science ]\n",
      "categories [Category Training, Category Deep Learning, Category Open Source Data Science, Category Beginner-Intermediate-Advanced]\n",
      "\n",
      "title AI for Executives\n",
      "day april-30th\n",
      "time 14:00\n",
      "datetime 2019-04-30 14:00:00\n",
      "excerpt Gain insight into how to drive success in data science. Identify key points in the machine learning life cycle where executive oversight really matters. Learn effective methods to help your team deliver better predictive models, faster. You'll leave this seminar able to identify business challenges well suited for machine learning, with fully defined predictive analytics projects your team can implement now to improve operational results.\n",
      "presenter_bio \n",
      "coming soon\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2017/08/John-Boersma.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/john-boersma-52b38810/\n",
      "presenter_title  PhD\n",
      "presenter_name John Boersma\n",
      "presenter_orgs [Organization  DataRobot]\n",
      "presenter_positions [Position Director of Education ]\n",
      "categories [Category Training, Category Data Science Management, Category Beginner-Intermediate-Advanced]\n",
      "\n",
      "title Synthesizing Data Visualization and User Experience\n",
      "day may-1st\n",
      "time 14:00\n",
      "datetime 2019-05-01 14:00:00\n",
      "excerpt The wealth of data available offers unprecedented opportunities for discovery and insight. How do we design a more intuitive and useful data experience? This workshop focuses on approaches to turn data into actionable insights by combining principles from data visualization and user experience design. Participants will be asked to think holistically about data visualizations and the people they serve. Through presentations and hands-on exercises, participants will learn how to choose and create data visualizations driven by user-oriented objectives.\n",
      "presenter_bio \n",
      "Bang Wong is the creative director of the Broad Institute of MIT and Harvard and an adjunct assistant professor in the Department of Art as Applied to Medicine at the Johns Hopkins University School of Medicine. His work focuses on developing strategies to meet the analytical challenges posed by the unprecedented volume, resolution, and variety of data in biomedical research.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2017/11/Bang-Wong.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/bangwong\n",
      "presenter_title None\n",
      "presenter_name Bang Wong\n",
      "presenter_orgs [Organization  Broad Institute of MIT-Harvard]\n",
      "presenter_positions [Position Creative Director ]\n",
      "presenter_bio \n",
      "Mark Schindler is co-founder and Managing Director of GroupVisual.io. For over 15 years, he has designed user-interfaces for analytic software products and mobile apps for clients ranging from Fortune 50 companies to early-stage startups. In addition to design services, Mark and his team mentor startup companies and conduct workshops on data visualization, analytics and user-experience design.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2019/01/Mark-Schindler-2019-120x120.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/mark-schindler-27419/\n",
      "presenter_title None\n",
      "presenter_name Mark Schindler\n",
      "presenter_orgs [Organization  GroupVisual.io]\n",
      "presenter_positions [Position Co-founder, Position  Managing Director ]\n",
      "categories [Category Workshops, Category  Data Visualization, Category  Beginner-Intermediate-Advanced]\n",
      "\n",
      "title Reproducible Data Science Using Orbyter\n",
      "day may-1st\n",
      "time 14:00\n",
      "datetime 2019-05-01 14:00:00\n",
      "excerpt Artificial Intelligence is already helping many businesses become more responsive and competitive, but how do you move machine learning models efficiently from research to deployment at enterprise scale? It is imperative to plan for deployment from day one, both in tool selection and in the feedback and development process. Additionally, just as DevOps is about people working at the intersection of development and operations, there are now people working at the intersection of data science and software engineering who need to be integrated into the team with tools and support. \n",
      "\n",
      "At Manifold, we've developed the Lean AI process to streamline machine learning projects and the open-source Orbyter package for Docker-first data science to help your engineers work as an an integrated part of your development and production teams. In this workshop, Sourav and Alex will focus heavily on the DevOps side of things, demonstrating how to use Orbyter to spin up data science containers and discussing experiment management as part of the Lean AI process.\n",
      "presenter_bio \n",
      "As CTO for Manifold, Sourav is responsible for the overall delivery of data science and data product services to make clients successful. Before Manifold, Sourav led teams to build data products across the technology stack, from smart thermostats and security cams (Google / Nest) to power grid forecasting (AutoGrid) to wireless communication chips (Qualcomm). He holds patents for his work, has been published in several IEEE journals, and has won numerous awards. He earned his PhD, MS, and BS degrees from MIT in Electrical Engineering and Computer Science.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2017/11/Sourav-Dey-e1543594278342.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/souravdeymit/\n",
      "presenter_title  PhD\n",
      "presenter_name Sourav Dey\n",
      "presenter_orgs [Organization  Manifold]\n",
      "presenter_positions [Position CTO ]\n",
      "presenter_bio \n",
      "Alexander Ng is a Senior Data Engineer at Manifold, an artificial intelligence engineering services firm with offices in Boston and Silicon Valley. Prior to Manifold, Alex served as both a Sales Engineering Tech Lead and a DevOps Tech Lead for Kyruus, a startup that built SaaS products for enterprise healthcare organizations. Alex got his start as a Software Systems Engineer at the MITRE Corporation and the Naval Undersea Warfare Center in Newport, RI. His recent projects at the intersection of systems and machine learning continue to combine a deep understanding of the entire development lifecycle with cutting-edge tools and techniques. Alex earned his Bachelor of Science degree in Electrical Engineering from Boston University, and is an AWS Certified Solutions Architect.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2018/11/Alex-Ng-PhD-120x120.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/alexander-b-ng/\n",
      "presenter_title  PhD\n",
      "presenter_name Alex Ng\n",
      "presenter_orgs [Organization  Manifold]\n",
      "presenter_positions [Position Senior Data Engineer ]\n",
      "categories [Category Workshop, Category AI for Engineers, Category Machine Learning, Category Intermediate]\n",
      "\n",
      "title Intermediate Machine Learning with scikit-learn\n",
      "day april-30th\n",
      "time 14:00\n",
      "datetime 2019-04-30 14:00:00\n",
      "excerpt Scikit-learn is a machine learning library in Python, that has become a valuable tool for many data science practitioners. This talk will cover some of the more advanced aspects of scikit-learn, such as building complex machine learning pipelines, model evaluation, parameter search, and out-of-core learning. Apart from metrics for model evaluation, we will cover how to evaluate model complexity, and how to tune parameters with grid search, randomized parameter search, and what their trade-offs are. We will also cover out of core text feature processing via feature hashing.\n",
      "presenter_bio \n",
      "Andreas Mueller received his MS degree in Mathematics (Dipl.-Math.) in 2008 from the Department of Mathematics at the University of Bonn. In 2013, he finalized his PhD thesis at the Institute for Computer Science at the University of Bonn. After working as a machine learning scientist at the Amazon Development Center Germany in Berlin for a year, he joined the Center for Data Science at the New York University in the end of 2014. In his current position as assistant research engineer at the Center for Data Science, he works on open source tools for machine learning and data science. He is one of the core contributors of scikit-learn, a machine learning toolkit widely used in industry and academia, for several years, and has authored and contributed to a number of open source projects related to machine learning.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2015/12/Andreas-Mueller-1.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/andreas-mueller-b370265a/\n",
      "presenter_title  PhD\n",
      "presenter_name Andreas Mueller\n",
      "presenter_orgs [Organization  Columbia Data Science Institute]\n",
      "presenter_positions [Position Author, Position  Lecturer, Position  Core Contributer of scikit-learn ]\n",
      "presenter_bio \n",
      "Thomas Fan is a Software Developer at Columbia University’s Data Science Institute. He collaborates with the scikit-learn community to develop features, review code, and resolve issues. On his free time, Thomas contributes to skorch, a scikit-learn compatible neural network library that wraps PyTorch.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2019/03/Thomas-Fan-1-120x120.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/thomasjpfan/\n",
      "presenter_title None\n",
      "presenter_name Thomas Fan\n",
      "presenter_orgs [Organization  Columbia Data Science Institute]\n",
      "presenter_positions [Position Software Developer - Machine Learning ]\n",
      "categories [Category Training, Category  Machine Learning, Category  Open Source Data Science, Category  Beginner-Intermediate]\n",
      "\n",
      "title Building AI-Based Emotional Detectors in Images and Text – A Hands-On Approach\n",
      "day may-1st\n",
      "time 14:00\n",
      "datetime 2019-05-01 14:00:00\n",
      "excerpt Deep Learning has become ubiquitous in everyday software applications and services. A solid understanding of DL foundational principles is necessary for researchers and modern-day engineers alike to successfully adapt the state of the art research in DL to business applications. \n",
      "\n",
      "In this workshop, we will cover the basics of Deep Learning, what deep learning can and cannot do. We will learn the applications of Deep Learning where it has achieved state of the art results viz., to Images and Text. \n",
      "The session will be a hands-on lab where attendees will use Apache MXNet to build an emotional detector in Images, we will cover basics of Convolutional Neural Networks applied to Computer Vision problems as we build the model.\n",
      "\n",
      "The attendees will also build a model that detects emotions(sentiments) in text data, we will cover the basics of Recurrent Neural Networks that is widely used to solve Natural Language Processing problems.\n",
      "\n",
      "The attendees will learn how to leverage the state of the art research to their application, best practices and tips, and tricks used by practitioners.\n",
      "presenter_bio \n",
      "Naveen is a Senior Software Engineer and a member of Amazon AI at AWS and works on Apache MXNet. He began his career building large scale distributed systems and has spent the last 10+ years designing and developing it. He has delivered various Tech Talks at AMLC, Spark Summit, ApacheCon and loves to share knowledge. His current focus is to make Deep Learning easily accessible to Software Developers without the need for a steep learning curve. In his spare time, he loves to read books, spend time with his family and watch his little girl grow.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2018/08/Naveen_Swamy-120x120.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/naveenswamy/\n",
      "presenter_title None\n",
      "presenter_name Naveen Swamy\n",
      "presenter_orgs [Organization  Amazon AI - AWS]\n",
      "presenter_positions [Position Software Developer ]\n",
      "categories [Category Training, Category AI for Engineers, Category Open Source Data Science, Category Beginner-Intermediate]\n",
      "\n",
      "title Data Visualization: From Square One to Interactivity\n",
      "day april-30th\n",
      "time 14:00\n",
      "datetime 2019-04-30 14:00:00\n",
      "excerpt As data scientists, we are expected to be experts in machine learning, programming, and statistics. However, our audiences might not be! Whether we're working with peers in the office, trying to convince our bosses to take some sort of action, or communicating results to clients, there's nothing more clear or compelling than an effective visual to make our point. Let's leverage the Python libraries Matplotlib and Bokeh along with visual design principles to make our point as clearly and as compellingly as possible!\n",
      "\n",
      "This talk is designed for a wide audience. If you haven't worked with Matplotlib or Bokeh before or if you (like me!) don't have a natural eye for visual design, that's OK! This will be a hands-on training designed to make visualizations that best communicate what you want to communicate. We'll cover different types of visualizations, how to generate them in Matplotlib, how to reduce clutter and guide your user's eye, and how (and when!) to add interactivity with Bokeh.\n",
      "presenter_bio \n",
      "Matt currently leads instruction for GA’s Data Science Immersive in Washington, D.C. and most enjoys bridging the gap between theoretical statistics and real-world insights. Matt is a recovering politico, having worked as a data scientist for a political consulting firm through the 2016 election. Prior to his work in politics, he earned his Master’s degree in statistics from The Ohio State University. Matt is passionate about making data science more accessible and putting the revolutionary power of machine learning into the hands of as many people as possible. When he isn’t teaching, he’s thinking about how to be a better teacher, falling asleep to Netflix, and/or cuddling with his pug.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2018/03/Matthew-Brems.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/matthewbrems/\n",
      "presenter_title None\n",
      "presenter_name Matt Brems\n",
      "presenter_orgs [Organization  General Assembly]\n",
      "presenter_positions [Position Global Lead Data Science Instructor ]\n",
      "categories [Category Training, Category Data Visualization, Category Machine Learning, Category Beginner-Intermediate-Advanced]\n",
      "\n",
      "title Artificial Intelligence in Finance\n",
      "day april-30th\n",
      "time 14:00\n",
      "datetime 2019-04-30 14:00:00\n",
      "excerpt Artificial Intelligence (AI) is about to reshape finance and the financial industry. Many decisions in the industry are already made by algorithms, such as in stock trading, credit scoring, etc. However, most of these applications do not harness the capabilities of recent advances in the field of AI.\n",
      "\n",
      "Today's programmatic availability of basically all historical and real-time financial data, in combination with ever more powerful compute infrastructures, facilitates the application of even the most advanced and compute intensive algorithms from AI to financial problems. In that sense, finance already is data-driven to a large extent these days. And it will become an AI-first discipline in the near future.\n",
      "\n",
      "The workshop provides some introductory background to AI in Finance. It then proceeds with the introduction to and application of different machine and deep learning algorithms to financial problems. The focus here lies on classification algorithms applied to the algorithmic trading of financial instruments. More specifically, the AI algorithms are used to create directional predictions about the future movements of financial prices.\n",
      "\n",
      "The workshop uses Python and standard packages such as NumPy, pandas, scikit-learn, Keras/TensorFlow and matplotlib. Most of the coding will be presented based on Jupyter Notebooks.\n",
      "presenter_bio \n",
      "Dr. Yves J. Hilpisch is founder and managing partner of The Python Quants, a group focusing on the use of open source technologies for financial data science, artificial intelligence, algorithmic trading, and computational finance. He is also founder and CEO of The AI Machine, a company focused on harnessing the power of artificial intelligence for algorithmic trading via a proprietary strategy execution platform. He is the author of Python for Finance (2nd ed., O’Reilly) and of two other books: Derivatives Analytics with Python (Wiley, 2015) as well as Listed Volatility and Variance Derivatives (Wiley, 2017). Yves lectures on computational finance at the CQF Program and on algorithmic trading at the EPAT Program. He is also the director of the first online training program leading to a University Certificate in Python for Algorithmic Trading. Yves wrote the financial analytics library DX Analytics and organizes meetups, conferences, and bootcamps about Python for quantitative finance and algorithmic trading in London, Frankfurt, Berlin, Paris, and New York. He has given keynote speeches at technology conferences in the United States, Europe, and Asia.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2019/01/Yves-Hilpisch-120x120.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/yves-hilpisch-74b43325/\n",
      "presenter_title  PhD\n",
      "presenter_name Yves Hilpisch\n",
      "presenter_orgs [Organization  Python Quants]\n",
      "presenter_positions [Position Founder , Position  Managing Partner ]\n",
      "categories [Category Training, Category  Machine Learning, Category  Quant Finance]\n",
      "\n",
      "title Building Recommendation Engines and Deep Learning Models Using Python, R and SAS\n",
      "day april-30th\n",
      "time 14:00\n",
      "datetime 2019-04-30 14:00:00\n",
      "excerpt Deep learning is the newest area of machine learning and has become ubiquitous in predictive modeling. The complex, brainlike structure of deep learning models is used to find intricate patterns in large volumes of data. These models have heavily improved the performance of general supervised models, time series, speech recognition, object detection and classification, and sentiment analysis.\n",
      "\n",
      "Factorization machines are a relatively new and powerful tool for modeling high-dimensional and sparse data. Most commonly they are used as recommender systems by modeling the relationship between users and items. For example, factorization machines can be used to recommend your next Netflix binge based on how you and other streamers rate content.\n",
      "\n",
      "In this session, participants will use recurrent neural networks to analyze sequential data and improve the forecast performance of time series data, and use convolutional neural networks for image classification. Participants will also use a genetic algorithm to efficiently tune the hyperparameters of both deep learning models. Finally, students will use factorization machines to model the relationship between movies and viewers to make recommendations.\n",
      "Demonstrations are provided in both R and Python, and will be administered from a Jupyter notebook. Students will use the open source SWAT package (SAS Wrapper for Analytics Transfer) to access SAS CAS (Cloud Analytic Services) in order to take advantage of the in-memory distributed environment. CAS provides a fast and scalable environment to build complex models and analyze big data by using algorithms designed for parallel processing.\n",
      "presenter_bio \n",
      "Coming Soon\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2018/10/Jordan-Bakerman-120x120.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/jordan-bakerman/\n",
      "presenter_title  PhD\n",
      "presenter_name Jordan Bakerman\n",
      "presenter_orgs [Organization  SAS]\n",
      "presenter_positions [Position Analytical Training Consultant ]\n",
      "presenter_bio \n",
      "Ari holds bachelor’s degrees in both physics and mathematics from UNC-Chapel Hill. His research focused on collecting and analyzing low energy physics data to better understand the neutrino. Ari taught introductory and advanced physics and scientific programming courses at UC-Berkeley while working on a master’s in physics with a focus on nonlinear dynamics. While at SAS, Ari has worked to develop courses that teach how to use Python code to control SAS analytical procedures.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2019/03/Ari-Zitin-120x120.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/ari-zitin-33938a74/\n",
      "presenter_title None\n",
      "presenter_name Ari Zitin\n",
      "presenter_orgs [Organization  SAS]\n",
      "presenter_positions [Position Sr. Analytical Training Consultant ]\n",
      "categories [Category Training, Category  Open Source Data Science, Category  Deep Learning, Category  Intermediate]\n",
      "\n",
      "title Automating Machine Learning Lifecycle with Kubeflow\n",
      "day may-1st\n",
      "time 16:00\n",
      "datetime 2019-05-01 16:00:00\n",
      "excerpt  \n",
      "During the workshop we are going to build and automate consequent stages of machine learning lifecycle, starting with data preparation and up to the model maintenance in production using Kubeflow, a machine learning toolkit for Kubernetes, and Hydrosphere.io, an open source machine learning models management platform.\n",
      "You will learn how to execute and automate the following steps:\n",
      "– Data preparation — perform data gathering and transformation to use it further for training;\n",
      "– Model training — train a new model upon a prepared data, using a predefined model architecture and save model’s artifacts;\n",
      "– Model cataloguing — extract model’s metadata from the trained model artifacts and upload them to Hydrosphere.io;\n",
      "– Model deployment — deploy an uploaded model to production and expose REST, gRPC and Kafka endpoints;\n",
      "– Integration testing — perform integration tests on your model on recent production traffic as well as on gathered edge cases;\n",
      "– Model monitoring — supply deployed model with monitoring services to watch its behaviour in production environment;\n",
      "– Model maintenance — repeatedly fine-tune your model with the most relevant production data;\n",
      "– Configuring ML pipelines, once it’s done properly, will save a lot of time and effort in ML engineers’ daily routines…\n",
      "\n",
      "presenter_bio \n",
      "Stepan Pushkarev is a CTO at Hydrosphere.io. His background is in engineering of data- and AI/ML platforms. He has spent last couple of years building continuous delivery and monitoring tools for machine learning applications as well as designing streaming data platforms. He works closely with data scientists to make them productive in their daily operations and efficient in delivering the value.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2018/10/stepan_pushkarev-120x120.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/stepanpushkarev/\n",
      "presenter_title None\n",
      "presenter_name Stepan Pushkarev\n",
      "presenter_orgs [Organization  Hydrosphere.io]\n",
      "presenter_positions [Position CTO ]\n",
      "categories [Category Workshops, Category Machine Learning, Category AI for Engineers, Category Intermediate]\n",
      "\n",
      "title The Lifecycle Of A Machine Learning Project: Sea Turtle Conservation And Predictive Modeling\n",
      "day may-1st\n",
      "time 16:00\n",
      "datetime 2019-05-01 16:00:00\n",
      "excerpt I will walk through all important steps of a machine learning project from problem definition and data collection to an interpretable predictive model and scientific/actionable insights in this tutorial. I will use an academic project to illustrate important concepts on \n",
      "- how to incorporate external datasets,\n",
      "- feature generation from time series data,\n",
      "- data exploration and visualization,\n",
      "- the importance of proper cross-validation approaches,\n",
      "- how to improve the interpretability of supervised machine learning models using XGBoost and SHAP values.\n",
      "\n",
      "We will analyze a rich dataset on the basking behavior of green sea turtles. This is a collaboration between data scientists at the Center for Computation and Visualization at Brown University and the Hawaii Wildlife Fund, a non-profit wildlife conservation organization. Green sea turtles are endangered marine animals that bask or rest on beaches. Maui’s Ho’okipa beach hosts one of the largest and densest basking aggregations in the state of Hawaii. Volunteers from the Hawaii Wildlife Fund are stationed at the beach from approximately 2:30 – 7:30pm every day of the year with the exception of severe weather conditions (hurricane force winds, etc.). They have been recording human visitor and basking turtle counts on the beach for years. \n",
      "\n",
      "The goals of the collaboration are to better understand the basking behavior of the turtles and to inform the Hawaii Wildlife Fund’s management and policy decisions with the use of predictive modeling.\n",
      "\n",
      "presenter_bio \n",
      "Andras Zsom is a Lead Data Scientist at the Center for Computation and Visualization at Brown University. He is managing a small but dedicated team of data scientists with the mission to help high level university administrators to make better data-driven decisions with data analysis and predictive modeling, we collaborate with faculty members on various data-intensive academic projects, and we also train data science interns.\n",
      "Andras is passionate about using machine learning and predictive modeling for good. He is an astrophysicist by training and he has been fascinated with all fields of the natural and life sciences since childhood. He was a postdoctoral researcher at MIT for 3.5 years before coming to Brown. He obtained his PhD from the Max Planck Institute of Astronomy at Heidelberg, Germany; and he was born and raised in Hungary.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2019/03/Andras-Zsom-120x120.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/andraszsom/\n",
      "presenter_title  PhD\n",
      "presenter_name Andras Zsom\n",
      "presenter_orgs [Organization  Advanced Research Computing at CCV, Organization  Brown University]\n",
      "presenter_positions [Position Lead Data Scientist ]\n",
      "categories [Category Tutorials, Category  Data Science for Good, Category  Research Bridge, Category  Intermediate]\n",
      "\n",
      "title Introduction To Face Processing With Computer Vision\n",
      "day may-1st\n",
      "time 16:00\n",
      "datetime 2019-05-01 16:00:00\n",
      "excerpt Ever wonder how Facebook’s facial recognition or Snapchat’s filters work?\n",
      "\n",
      "Faces are a fundamental piece of photography, and building applications around them has never been easier with open-source libraries and pre-trained models.\n",
      "\n",
      "In this talk, we’ll help you understand some of the computer vision and machine learning techniques behind these applications. Then, we’ll use this knowledge to develop our own prototypes to tackle tasks such as face detection (e.g. digital cameras), recognition (e.g. Facebook Photos), classification (e.g. identifying emotions), manipulation (e.g. Snapchat filters), and more.\n",
      "presenter_bio \n",
      "Gabriel is the founder of Scalar Research, a full-service artificial intelligence & data science consulting firm. Scalar helps companies tackle complex business challenges with data-driven solutions leveraging cutting-edge machine learning and advanced analytics.\n",
      "Previously, Gabriel was a B.S. & M.S. student in computer science at Stanford, where he conducted research on computer vision, deep learning, and quantum computing. He’s also spent time at Google, Facebook, startups, and investment firms.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2019/03/Gabriel-Bianconi-120x120.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/gabrielbianconi\n",
      "presenter_title None\n",
      "presenter_name Gabriel Bianconi\n",
      "presenter_orgs [Organization  Scalar Research]\n",
      "presenter_positions [Position Founder ]\n",
      "categories [Category Workshops, Category  Machine Learning, Category  Open Source Data Science, Category  Beginner – Intermediate]\n",
      "\n",
      "title How To Actually *Do* Data Privacy\n",
      "day may-1st\n",
      "time 16:00\n",
      "datetime 2019-05-01 16:00:00\n",
      "excerpt Data privacy and AI ethics have been the subject of satire in The Onion. This is a sign that we've spent more time talking about data privacy than enacting practices that empower our data subjects to modulate what they share, for how long, and to which purposes.\n",
      "\n",
      "In this talk, I will walk through four key practices for dealing with data ethically, in workshop style:\n",
      "     0. Define your data stakeholders.\n",
      "     1. Empower your data stakeholders to see, amend, selectively delete, and globally delete data that represents them. We will sort through legal tensions between retention and deletion requirements and discuss deploying automated decay by design tools to expunge privacy-sensitive data that has little value to the business.\n",
      "     2. Accompany model accuracy testing with and model fairness assessments. We’ll walk through schemas for assessing which fairness threshold is appropriate for a given intervention.\n",
      "     3. Add annual fairness, privacy, and transparency reports to board meeting agendas. Share publicly. A template will be provided.\n",
      "\n",
      "Participants should leave the workshop with a clear set of technical and corporate tasks to move them into an active practice around data privacy and the ethical deployment of automated decision making. Some of objectives align with requirements in privacy regulations such as GDPR and CCPA, but this is not a compliance workshop. It is an engineering, product development, and ethics workshop.\n",
      "presenter_bio \n",
      "Laura Norén is a data science ethicist and researcher currently working in cybersecurity at Obsidian Security in Newport Beach. She holds undergraduate degrees from MIT, a PhD from NYU where she recently completed a postdoc in the Center for Data Science. Her work has been covered in The New York Times, Canada’s Globe and Mail, American Public Media’s Marketplace program, in numerous academic journals and international conferences. Dr. Norén is a champion of open source software and those who write it.\n",
      "\n",
      "presenter_image https://odsc.com/wp-content/uploads/2018/08/Laura-Noren-120x120.jpg\n",
      "presenter_linkedin https://www.linkedin.com/in/laura-noren-93a846145/\n",
      "presenter_title  PhD\n",
      "presenter_name Laura Noren\n",
      "presenter_orgs [Organization  Obsidian Security & NYU Stern School of Business]\n",
      "presenter_positions [Position Director of Research & Professor\t]\n",
      "categories [Category Workshops, Category Data for Good, Category Open Source Data Science, Category Intermediate ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for item in page.items:\n",
    "    print(\"title \" + item.title)\n",
    "    print(\"day \" + item.day)\n",
    "    print(\"time \" + str(item.time))\n",
    "    print(\"datetime \" + str(item.datetime))\n",
    "    print(\"excerpt \" + str(item.excerpt))\n",
    "    for presenter in item.presenters:\n",
    "        print(\"presenter_bio \" + presenter.presenter_bio)\n",
    "        print(\"presenter_image \" + str(presenter.presenter_image))\n",
    "        print(\"presenter_linkedin \" + str(presenter.presenter_linkedin))\n",
    "        print(\"presenter_title \" + str(presenter.title))\n",
    "        print(\"presenter_name \" + str(presenter.name) )\n",
    "        print(\"presenter_orgs \" + str(presenter.organizations))\n",
    "        print(\"presenter_positions \" + str(presenter.positions))\n",
    "    print(\"categories \" + str(item.categories) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for item in page.items:\n",
    "    for presenter in item.presenters:\n",
    "        if presenter.presenter_bio is None:\n",
    "            print(\"title \" + item.title)\n",
    "            print(\"day \" + item.day)\n",
    "            print(\"time \" + str(item.time))\n",
    "            print(\"datetime \" + str(item.datetime))\n",
    "            print(\"excerpt \" + str(item.excerpt))\n",
    "            print(\"categories \" + str(item.categories) + \"\\n\")\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page.updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page.soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"may-1st\".strip('st')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = \"<p>ligfiuewbfiuewbfiewfbwuebfwubfwbflwb<a href='#'></a></p>\"\n",
    "some_soup = BeautifulSoup(html, \"lxml\")\n",
    "some_soup.p.contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[1,1,1,1,2].pop(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 ODSC APP",
   "language": "python",
   "name": "odsc_app"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
